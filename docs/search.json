[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "RMS textbook",
    "section": "",
    "text": "Preface\nHello and welcome to Dr. Pilot’s Research Methods and Statistics courses. This online textbook is a companion to the in class experience. It was created as a tool you can use when you’re at home to practice R, review terms, and prepare for upcoming evaluations.\nThis text will cover the following topics and more:\n\nInstalling and setting up R on your device\nBasic R vocabulary and use\nManipulating data\nVisualizing data\nResearch design\nResearch methods\nMeasurement\nUnivariate analysis\n(some) Multivariate analysis\n\nFinally, this is a living text, it is incomplete. There will be typos, inelegant language, and sometimes things may not appear the way I intend. Just let me know so I can improve it.\nThis book began as a collaboration between Dr. Pilot, Liam Murray, and Jacob Lucas.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "setup.html",
    "href": "setup.html",
    "title": "1  Setup",
    "section": "",
    "text": "1.1 Download R\nR is used in this course for several reasons.\nNow that we are convinced, lets get R on all of our personal devices.\nWhen we say R, we are often referring to both R and R Studio. R studio is a program that makes R much easier to use, and that’s usually what we’re referring to…but we need R for R Studio to work.\nR typically has a major update once a year and several smaller updates throughout the year. When these come out you have to download all of your packages again, but it’s good to keep it updated. Link to download R.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "setup.html#download-r-studio",
    "href": "setup.html#download-r-studio",
    "title": "1  Setup",
    "section": "1.2 Download R Studio",
    "text": "1.2 Download R Studio\nWe will do all of our work in R Studio, download it here, after base R has been downloaded. It also has several updates a year, but it doesn’t change anything about the packages so keep it updated.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "setup.html#r-studio-overview",
    "href": "setup.html#r-studio-overview",
    "title": "1  Setup",
    "section": "1.3 R Studio Overview",
    "text": "1.3 R Studio Overview\nOnce you open Rstudio you might notice that there are four different panes on your screen that each look different from the other. Although it might look overwhelming these panes are all important when operating in Rstudio and will all be used.\n\n1.3.1 Console Frame\nThe console frame is the bottom left frame on your screen. The console is like a scrap piece of paper or and etch an sketch, its a great place to do some troubleshooting or viewing data through the glimpse() function but any work you do here will not be saved. To run your code in the console frame you type the code and press the enter or return key. You can also see output from your code directly in this frame. The console is also next to the terminal which is the tab right next to it. They both can run commands but are different in nature.The console is intended to run commands that work mainly inside Rstudio itself. The terminal however runs systems commands like something you do on your computer.\n\n\n\n\n\n\n\n\n\n\n\n1.3.2 Source Frame\nThe source frame or editor frame is the top left frame on your screen. This frame is the primary location of where you will be doing your work and typing all of your code. The source frame is used to open RMarkdown documents, scripts, and other ways to type code. You can also save and open new documents and files at the farthest top left corner of this frame.\n\n\n\n\n\n\n\n\n\n\n\n1.3.3 Environment/History\nThe environment or history frame can be seen in the top right frame on your screen. This is where you can view current objects that you have created which we will discuss further in the chapter as well as data sets and where you can track your steps by viewing the command history that you have run.\n\n\n\n\n\n\n\n\n\n\n\n1.3.4 Files/Packages\nThe last frame on the bottom right is your files and packages frame. This frame is more of a window into your computer in the sense that you are able to view the packages and files that you have on stored on it. You can also use it to check any plots you might have and to read any documents on your computer as well. You only need to download a package one time, then it is saved. However, every time you open Rstudio packages must be loaded into the R environment.\n\n\n\n\n\n\n\n\n\n\n\n1.3.5 Customization\nR is more fun when it looks the way you want it to. By default R doesn’t emphasize the different between fucnitons and arguments and the text within them, but some fonts do. I suggest you change your font to somethign that helps readability. Click Tools &gt; Global Options &gt; Appearance then click through some fonts.\nSuggestion: Some fonts like “Dawn” do not use a lot of contrast between types of information, so I would avoid those.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "setup.html#saving",
    "href": "setup.html#saving",
    "title": "1  Setup",
    "section": "1.4 Saving",
    "text": "1.4 Saving\nScience should be reproducible, so should your work. When you close R and start a new session you will be starting from a blank slate unless you save your work.\nBy default, R will save your work in a working directory, The working directory is a location on your computer or the cloud. See where your things are being saved by typing getwd() in the source pane now. This is probably not a good place to save the many files we will be creating in this course. Instead, we will create an R Studio Project.\n\n1.4.1 R Studio Project\nFollow the steps below to create an R Studio project where all of your things will be saved.\n\nAbove the console pane you will see several clickable buttons with green pluses on them. Click the second button from the left to create a new project.\nClick “New Directory”\nClick “New Project”\nName your project something like “rms” or “psy303”\nChoose a sensible subdirectory by clicking the “Browse” button so you can find all of your files. I suggest your desktop on your device, not the cloud.\nClick “Create Project”\n\nNow, you should notice in the top right of your screen the name of your project, indicating that you are working within that project.\n\n\nCheck your new working directory by typing getwd() in the source pane again, it should reflect your subdirectory and project name.\nAs long as this project is open everything you save, which we will get to in the sections below, will be placed in that working directory and you will have easy access to anything in that directory from R. We will be creating code documents in this class from a package called RMarkdown. But to get there we need to understand what packages are.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "setup.html#packages",
    "href": "setup.html#packages",
    "title": "1  Setup",
    "section": "1.5 Packages",
    "text": "1.5 Packages\nNow that you are familiar with the R interface we will get into the things that make R run, packages.\n\n1.5.1 What is a package?\nA package is where R gets its main power. Packages are compilations of data, functions, etc. that we must download from CRAN - the Comprehensive R Archive Network. Packages can contain lots of different things. They are most useful because they allow us to perform actions we can do with base R alone- which is just R without any packages downloaded.\n\n\n1.5.2 Installing and finding packages\nThere are two ways to install packages. Install both of these packages because we will be using them a lot.\n\nVia your files and packages pane.\n\nClick the packages tab in the Files/Packages pane\nClick the install button on the top left of that pane\ntype “rmarkdown”\nclick install\n\nVia code.\n\nclick to the right of the &gt; symbol in your bottom left console pane\nuse the install.packages() function to install the desired package\nOnce you are there you will type the following code. Do not be afraid if you see a warning in yellow that is perfectly normal.\n\n\n\ninstall.packages(\"tidyverse\")\n\n\n\n1.5.3 R Markdown\nNow that we have R Markdown downloaded we are going to open a markdown document.\n\nLook to the upper left of the console pane, you should see a white page with a green plus arrow over top of it. Click it.\nIn the dropdown menu click “R Markdown”.\nYou will be prompted to name your document - usually you want this to be obvious and helpful. For now, call it “fundamentals”\n\nYour document should open and it will be automatically filled with some stuff. Do not be alarmed, you can do many things in R Markdown, but we will start out slow.\n\n1.5.3.1 Source/Visual Editor\nAbove the document itself, just under the save icon, you should see the words “Source” and “Visual”. These are buttons that change your view from the source code view and a rendered view that works more like Microsoft Word.\nClick back and forth.You should notice some differences. What is most important for us is the use of ##. These tell Markdown to make a header. It’s super useful when organizing your code.\nWe will be staying in the Source editor.\n\n\n1.5.3.2 YAML Header\nAt the very top of the document you see a YAML header, this formats your document. For now, we will leave it be.\n —  \ntitle: “Untitled”  \nauthor: “zp”  \ndate: “2026-01-11”  \noutput: html_document\n —\n\n\n1.5.3.3 Code Chunks\nImmediately below the header is the first code chunk. Code chunks are placed within a Markdown document where code can be executed. Text outside of a code chunk is interpreted just like a word processor - so code doesn’t work.\nCode chunks always begin with ```{r}\nand end with ```\nYou can name code chunks for organization, the first chunk in this markdown document is named “setup”. The next thing, “include = false” tells markdown to do something specific with that code chunk. In this case, it’s saying run this code in the background, but don’t show the viewer.\nCode chunks can be customized in various ways. For example, in this textbook I make lots of code visible, but I choose to hide the output.\nIn this class you should never have one incredibly long code chunk. They should be used to complete one specific task that is explained via the word processing and then moving on to the next task and repeating the process.\nTo create a code chunk you can click the green C with button to the top right of the Source frame or you can use the keyboard shortcut option + command + i.\nWhen code is typed into a code chunk it doesn’t run when you press enter like in the console. In RMarkdown you are writing a kind of script - code that is meant to be executed all at once at the end. However, that’s not how people work. Often, you will need to run the current chunk you are working on. When working in Markdown the code chunks you create have acccess to any object you have saved in the environment and any package you have loaded that session. There are two ways run code in R markdown.\n\nPress the little green play button in the top right corner of the code chunk.\nClick anywhere in the code you want to run and use the keyboard shortcut shift + command + return\n\n\n\n1.5.3.4 Text\nJust below the code chunk we see ## R Markdown. This tells markdown to make a second level header named R markdown. We can see this if we switch to the Visual editor.\nJust below that is normal text.\nThat’s all we need to understand for now. When you open these documents you can delete everything but the YAML header. So let’s do that now and use the Markdown file you created for the remainder of this chapter and the fundamentals chapter.\n\n\n\n1.5.4 Loading packages\nWhen you download a package it is on your computer until you delete it or until you update R. However, when you start a new session you will not have access to that function, the package will need to be loaded. In order to use the functions within a package you must load it into the R environment every single time. For us, that means the first code chunk of our R Markdown files is just loading in the packages we will need for that document.\nPackages are loaded into the environment by using the the library() function. It will not work if you do not have the package installed.\n\nlibrary(tidyverse)\n\nOnce you have successfully loaded the tidyverse into your current session you should get the following result in your console:\n\n\n\n\n\n\n\n\n\nTHIS IS OK IT MEANS YOU HAVE SUCCESFULLY LOADED YOUR PACKAGE\nSometimes you will need to update your packages. You can do this by executing the code below in your console or within a markdown document or you can click the green update button in the packages pane.\n\nupdate.packages()\n\nTo see what packages you have installed you can either go to the bottom right pane and find the packages tab to find a list of all packages and which are installed. Or you could also run this code.\n\ninstalled.packages()",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Setup</span>"
    ]
  },
  {
    "objectID": "fundamental_r_use.html",
    "href": "fundamental_r_use.html",
    "title": "2  Fundamentals of R",
    "section": "",
    "text": "2.1 Introduction\nThis chapter will go over the fundamental tools you will need in order to work in R and to create projects and to experiment with the building blocks of Rstudio. If you have not already gone to chapter one that teaches you how to set up Rstudio do that now.\nOpen up an R markdown file, name it appropriately, and follow a long with the exercises below.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals of R</span>"
    ]
  },
  {
    "objectID": "fundamental_r_use.html#introduction",
    "href": "fundamental_r_use.html#introduction",
    "title": "2  Fundamentals of R",
    "section": "",
    "text": "How to create and manipulate data.\nHow to use functions, objects, and pipes.\nCommon errors and different ways to deal with them.\nAnd the main types of data that you will be running into in Rstudio.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals of R</span>"
    ]
  },
  {
    "objectID": "fundamental_r_use.html#objects",
    "href": "fundamental_r_use.html#objects",
    "title": "2  Fundamentals of R",
    "section": "2.2 Objects",
    "text": "2.2 Objects\nIn R, we will primarily be working with objects. An object is a container that you label. It can be a single number, a giant dataset, a graph, a function or even models that we need. In order to create an object we use the assignment operator, it looks like an arrow pointing to the left &lt;-. The assignment operator creates an object with the name of whatever is to the left of the operator and it will contain whatever is to the right of the operator.\n\nx &lt;- 67 # object named x that contains the number 67\ny &lt;- \"Good Morning\" # object named y that contains the string \"Good Morning\"\n\nIf i make changes to an object that I want to keep, I must rewrite the original object or create a new one. If not, then my changes are not saved.\n\nx # open the x object\n\n[1] 67\n\nx + 3 # add three to get 70, but don't assign to new object\n\n[1] 70\n\nx # x is still 67\n\n[1] 67\n\nx &lt;-  x + 3 # make a new object named x using the old x object plus 3\n\nx # the x object is 70 now\n\n[1] 70\n\n\n\n2.2.1 Listing objects\nIf you ever want to see what your current objects are you can always look in your environment frame. You can also use the list function ls().\n\nls()",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals of R</span>"
    ]
  },
  {
    "objectID": "fundamental_r_use.html#functions",
    "href": "fundamental_r_use.html#functions",
    "title": "2  Fundamentals of R",
    "section": "2.3 Functions",
    "text": "2.3 Functions\nNow that we are able to successfully load packages we can start looking at some functions. A function is a command that begins an action. This is a basic example of a function. The function is made up of two arguments that we give values to.\n\nfunction_name(argument1 = value1, argument2 = value2)\n\n\n2.3.1 Applied Functions\nNext we can look at a basic function called combine or c(). It takes every value in the function and groups them in what is called a vector, more on that later. This can be used for mathematical purposes when using Rstudio like a calculator. Lets take a look at an example.\n\n# Create object x that is a vector (a list) of numbers\nx &lt;- c(1, 2, 3, 4, 5)\nx\n\n[1] 1 2 3 4 5\n\n\n\n\n2.3.2 Arguments\nFunctions require certain information to carry out their actions. Arguments are where we provide that information. Many functions have default values automatically used for arguments. However, we often have to supply information for arguments, even if it’s just the name of the object we want to use the function on. Arguments are separated by a comma. Let’s look at the sum function. It has two arguments, the first is the data itself or the vector object containing the data and the second is na.rm = which has a default value of FALSE. na.rm is a logical argument asking if we want to remove data coded as NA, which could be missing data or incompatible data. Default arguments don’t need to be typed out, they are implied, unless we want to give a value to the argument other than the default.\n\nx &lt;- c( 1, 2, 3, 4, 5)\nsum(x) # no need to specify na.rm here\n\ny &lt;- c(1, 2, 3, 4, 5, NA)\nsum(y) # R can't calculate the sum if it doesn't know the value of NA\nsum(y, na.rm = TRUE) # fixed\n\n\n\n2.3.3 Creating Functions\nCreating your own function is a very useful skill because it allows you to easily apply values to data without having to type it out over and over again. In order to create a function you must name it then assign it a value by using the &lt;- symbol. This assigns whatever you write to that name which then should appear in the top right frame or your environment frame.\n\nplus_two &lt;- function(x) {\n  x + 2\n}\n\nplus_two(5)\n\n[1] 7\n\n\nWe created the function plus_two, which will take whatever is in our function (x) and add 2 to it so when we use the function and put 5 in there it takes 5 and adds two.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals of R</span>"
    ]
  },
  {
    "objectID": "fundamental_r_use.html#creating-data",
    "href": "fundamental_r_use.html#creating-data",
    "title": "2  Fundamentals of R",
    "section": "2.4 Creating Data",
    "text": "2.4 Creating Data\n\n2.4.1 Vectors\nA vector is a simple data structure that holds elements of the same kind. So if we want to combine a bunch of names we can use a vector to do so. We will go over the different types of data later in the chapter. Here are some simple basic examples of vectors.\n\nnumbers &lt;- c(1, 2, 3, 4, 5, 6, 7)\nnames &lt;- c(\"Adam\", \"Steven\", \"James\")\n\nNow once we have these saved as objects we can use them again since we have combined them all into one vector.\n\nsum(numbers)\n\n[1] 28\n\n\n\n\n2.4.2 Data Frames\nA data frame is arranged into a rectangular shape and uses rows and columns. The columns in a data frame are called variables and the rows in our data frame are called observations. Now we can use data frames to combine two different types of data into one object. The data.frame() function creates this framework for us. We create columns and observations in this format:\n\ndata.frame(\n  column_1 = c(obs_1, obs_2, obs_3), \n  column_2 = c(obs_1, obs_2, obs_3)\n)\n\nLet’s put some data in there.\n\ndf &lt;- data.frame(\n  name = c(\"James\", \"Henry\"),\n  age = c(21,67),\n  sport = c(\"Baseball\", \"Soccer\")\n)\n\nNotice we have three columns and two observations. All information in a row is part of one observation. So, James is 21 and his sport is Baseball.\n\n\n2.4.3 Tibbles\nTibble is short for transposed table and it is a different way to create small data frames that looks more like a spreadsheet. It requires the tibble package to work, but that’s part of the tidyverse so we should be ok. Some functions will only take data formatted as tibbles.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\npeople &lt;- tribble(\n  ~name,   ~age, ~city,\n  \"James\",  21,   \"Evansville\",\n  \"Hunter\", 38,   \"Toledo\"\n)\n\npeople\n\n# A tibble: 2 × 3\n  name     age city      \n  &lt;chr&gt;  &lt;dbl&gt; &lt;chr&gt;     \n1 James     21 Evansville\n2 Hunter    38 Toledo    \n\n\nNow you can see our tibble fully completed with both rows and columns where you can see in the bottom of the output that the tibble shows the rows. It also tells us the type of data that we are seeing in the output which you will learn more about later.\n\n\n2.4.4 glimpse()\nglimpse() is used to examine the characteristics of your data, it provides a summary for your data object that includes the column names, the type of data in that column, and several of the first observations in that column.\n\nglimpse(people)\n\nRows: 2\nColumns: 3\n$ name &lt;chr&gt; \"James\", \"Hunter\"\n$ age  &lt;dbl&gt; 21, 38\n$ city &lt;chr&gt; \"Evansville\", \"Toledo\"\n\n\nLook at the output above you can see next to name the &lt;chr&gt; that means the column contains data that is characters. The one below that is the &lt;dbl&gt; so you can see that is double data. Lets talk about what these different data types are.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals of R</span>"
    ]
  },
  {
    "objectID": "fundamental_r_use.html#types-of-data",
    "href": "fundamental_r_use.html#types-of-data",
    "title": "2  Fundamentals of R",
    "section": "2.5 Types of data",
    "text": "2.5 Types of data\nIn statistics we use numbers to represent all kinds of different things. We must differentiate between when a number 3 is representing a third category or the result of 1 + 2.\n\n2.5.1 Numeric and Double data\nNumeric data is a type of data that represents integers and “double precision floating point” numbers….or decimals. These are pretty common and are just regular numbers as you are familiar with them. They exist on a number line, can be multiplied and divided, and so on. Data formatted as numeric or double are on interval or ratio scales of measurement.\nWe can see if the data we are looking at is numeric/double by looking for how it is abbreviated. You can use the typeof() function in R to see exactly what type of data you are dealing with when you have a question about single objects, like below.\n\ntypeof(42)\n\n[1] \"double\"\n\ntypeof(FALSE)\n\n[1] \"logical\"\n\ntypeof(\"jack\")\n\n[1] \"character\"\n\n\nIf we use the glimipse() function we can see how we will more commonly interact with data formats.\n\nx &lt;- c(1 , 2, 3, 4, 5)\nglimpse(x)\n\n num [1:5] 1 2 3 4 5\n\n\n\n\n2.5.2 Character data\nCharacter data is words that are not functions. Character data may also be referred to as “string” data. As behavioral scientists we may ask participants to write a response, this would be stored as character data. We can tell if the data is a character because it must always be in \"\" . This shows that it is just text we are dealing with and not a function. The abbreviation for character data in R is chr.\n\nmy_vector &lt;- c(\"apple\", \"banana\", \"cherry\")\ntypeof(\"apple\")\nglimpse(my_vector)\n\n\n\n2.5.3 Logical data\nLogical data can only represent one of two values, TRUE or FALSE. This is referred to as Boolean data. It is important that they are all capitalized so they cannot be confused for something else. The abbreviations in R are simple because it will either be T or F.\n\n# Assigning logical values using full names\nbool1 &lt;- TRUE\nbool2 &lt;- FALSE\ntypeof(bool1)\n\n# Assigning logical values using abbreviations\nbool3 &lt;- T\nbool4 &lt;- F\ntypeof(bool4)\n\n\n\n2.5.4 Factor data\nData are formatted as factors when we are referring to categories. It works with variables that have a fixed and already known set of possible values. We use factor data differently depending on the data we have. Data formatted as a factor can be on an ordinal scale or a nominal scale. We use factor() to create a new factor from a vector. We use as.factor() to move an object like a character list into a vector.\n\ncollege &lt;- c(\"freshman\", \"sophomore\", \"junior\", \"senior\")\nglimpse(college) # notice that R formats this as a character vector\n\ncollege_fct &lt;- factor(college)\nglimpse(college_fct) # now it is a factor, but the order of the levels is wrong\n\ncollege_fct &lt;- factor(college, levels = c(\"freshman\", \"sophomore\", \"junior\", \"senior\"))\nglimpse(college_fct) # now the order is right\n\n# factors can also be numbers\n\ndata &lt;-  c(1, 2, 3, 4, 5)\nfactor(data)",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals of R</span>"
    ]
  },
  {
    "objectID": "fundamental_r_use.html#the-pipe",
    "href": "fundamental_r_use.html#the-pipe",
    "title": "2  Fundamentals of R",
    "section": "2.6 The pipe",
    "text": "2.6 The pipe\nThe pipe is an incredibly important part of writing useful code in R. It is symbolized by %&gt;% or |&gt;. Whenever we are running multiple functions in a code chunk we use the pipe to channel the output right into the first argument of the next function without having to do the work ourselves. The pipe is easily created within a code chunk by using the shortcut command + shift + m. Click the help tab above to see more keyboard shortcuts. Now lets look at an example of how the pipe works.\n\nmtcars %&gt;% # a dataset about car characteristics\n  group_by(cyl) %&gt;% # group the dataset by how many cylinders the cars have\n  summarize(mean_mpg = mean(mpg)) # create a new column for average miles per gallon by group\n\nYou can see in the output that by using the pipe we loaded the car data set then used it as the first argument of the group_by() function, then took that output and used it as the first argument for the summarize() function. We will go into more detail about these functions in the Data Wrangling chapter.\nNow try running the same code without the use of the pipe and see if it still works.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals of R</span>"
    ]
  },
  {
    "objectID": "fundamental_r_use.html#tips-and-trouble-shooting",
    "href": "fundamental_r_use.html#tips-and-trouble-shooting",
    "title": "2  Fundamentals of R",
    "section": "2.7 Tips and trouble shooting",
    "text": "2.7 Tips and trouble shooting\nWhen working with R there is always going to be something that will end up needing fixing or something will go wrong and you don’t know what to do. That is OK because there are a few different ways to figure things out when you need help.\n\n2.7.1 ? Tool\nThe question mark tool can help explain anything you need. Lets say for example you don’t know what a mean is. You can type in ?mean and the help tab in your bottom right frame will open with whatever you need.\n\n?mean\n\n\n\n2.7.2 Help\nThe help function is another way to get info on objects you might be struggling with. It works the same as ? and can give you more information on it.\n\nhelp(\"mean\")\n\n\n\n2.7.3 Traceback\nWhenever we are working in R sometimes we will get errors. This can be confusing because R doesn’t always tell you where you made this error it usually tells you what is wrong and when you are writing lots of code it can be difficult to find where you went wrong. Well you can use the traceback() function to find exactly where your code stopped working.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals of R</span>"
    ]
  },
  {
    "objectID": "fundamental_r_use.html#practice",
    "href": "fundamental_r_use.html#practice",
    "title": "2  Fundamentals of R",
    "section": "2.8 Practice",
    "text": "2.8 Practice\nNow that you learned the basic fundamentals of R and operating inside of it here are some practice problems to make yourself more comfortable with working in R\n\nCreate a tribble() with four of your friends names, ages, and cities they are from\nUse glimpse() to inspect the data\nWrite a function that doubles any number\nUse the pipe to select certain columns\nFind and list each columns type of data",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Fundamentals of R</span>"
    ]
  },
  {
    "objectID": "data_wrangle.html",
    "href": "data_wrangle.html",
    "title": "3  Data Wrangling",
    "section": "",
    "text": "3.1 Introduction\nThe tidyverse is filled with functions that help us work with data. Most of the functions covered here come from the dplyr package.\nDatasets in R have rows and columns. Rows are the participants, cases, or observations and columns are the variables. Dplyr has certain functions, sometimes referred to as verbs, to handle this information.\nIn the grammar of dplyr, the first argument is always your data frame object. The following arguments describe what to do with that data frame. The result of a dplyr function is always a new data frame.\nThere are two verbs used on columns: select() and mutate()\nThere are two verbs used for rows: filter() and arrange()\nThere are two verbs used for summary: group_by() and summarise()",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "data_wrangle.html#introduction",
    "href": "data_wrangle.html#introduction",
    "title": "3  Data Wrangling",
    "section": "",
    "text": "3.1.1 Logical Operators\nWe can use logical operators within dplyr to help manipulate our data.\nBelow is a list of logical operators.\n\n\n\nOperator\nDescription\n\n\n\n\n&lt;\nless than\n\n\n&lt;=\nless than or equal to\n\n\n&gt;\ngreater than\n\n\n&gt;=\ngrater than or equal to\n\n\n==\nexactly equal to\n\n\n!=\nnot equal to\n\n\n!x\nNot x\n\n\nx | y\nx OR y\n\n\nx & y\nx and y\n\n\nisTRUE(x)\ntest if x is TRUE\n\n\n\n\n\n3.1.2 Pipes\nPipes are super useful, they may look like this %&gt;% or this |&gt; . Both are fine.\nI recommend using the keyboard shortcut for pipes because they’re annoying to type. Shortcuts can be found in the Help menu at the top of the screen.\nThe pipe passes the object on its left to the first argument of the function to the right of the pipe. In dplyr, the first argument of anything is a data frame, so it’s useful to know. It helps me to think of the pipe as saying “and then”. So, in my head I read the code below as “load the package tidyverse, then load the diamonds data frame object and then count the rows in that object.”\n\nlibrary(tidyverse)\n\ndiamonds |&gt; \n  count()",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "data_wrangle.html#functions-used-on-columns",
    "href": "data_wrangle.html#functions-used-on-columns",
    "title": "3  Data Wrangling",
    "section": "3.2 Functions used on columns",
    "text": "3.2 Functions used on columns\n\n3.2.1 select()\nThe select() function chooses which columns we want to keep from a larger data frame.\n\n# load psych package that contains sat.act data\nlibrary(psych)\n\n# check out all the variables in the data frame\nglimpse(sat.act)\n\n# choose only gender and ACT\nsat.act |&gt; \n  select(gender, ACT)\n\n# choose everything but ACT\nsat.act |&gt; \n  select(!ACT)\n\n# choose everything from gender to age\nsat.act |&gt; \n  select(gender:age)\n\n# choose everything that starts with SA\nsat.act |&gt; \n  select(starts_with(\"SA\"))\n\n# choose everything that ends with T\nsat.act |&gt; \n  select(ends_with(\"T\"))\n\n# choose everything that has a t in it\nsat.act |&gt; \n  select(contains(\"T\"))\n\n\n\n3.2.2 rename()\n[will do this later]\n\n\n3.2.3 relocate()\n[will do this later]\n\n\n3.2.4 mutate()\nmutate() is used to change existing columns or create new columns. Mutate is very useful when making subscales, calculating totals, etc.\n\n# look at the data \n\nglimpse(USArrests)\n\n# create a new variable for all violent crime \n# by default the new column as added to the end of the data frame\nUSArrests |&gt; \n  mutate(violent_crime = (Murder + Assault + Rape))",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "data_wrangle.html#functions-used-on-rows",
    "href": "data_wrangle.html#functions-used-on-rows",
    "title": "3  Data Wrangling",
    "section": "3.3 Functions used on rows",
    "text": "3.3 Functions used on rows\n\n3.3.1 case_when()\n[ will do this later]\n\n\n3.3.2 case_ match()\n[ will do this later]\n\n\n3.3.3 if_else()\n\n\n3.3.4 filter()\nfilter() is used at the ROW level, so it will not change the columns we see. filter() tells us which kind of participant data to include and exclude. This is especially useful if we want to exclude certain observations from our analyses (like outliers) or only look at as a subset of our data.\nLet’s stick with the arrests data and only keep the data from states that are more than 50% urban population.\n\n# 42 states with over 50% urban population\nUSArrests |&gt; \n  filter(UrbanPop &gt;50)\n\nLet’s do a little more with the diamonds data set.\n\n# only diamonds over 1 carat in size\n# still 17k\ndiamonds |&gt; \n  filter(carat &gt; 1)\n\n# typing ?diamonds allows me to see what is the best diamond qualities\n# I only want THE BEST\ndiamonds |&gt; \n  filter(carat &gt;1 & cut == \"Ideal\" & color == \"D\" & clarity == \"IF\")\n\n# I'll compromise a little - by using %in% I get all very good and ideal cuts\ndiamonds |&gt; \n  filter(carat &gt;1 & (cut %in% c(\"Ideal\", \"Very Good\")) & color == \"D\" & clarity == \"IF\")\n\n\n\n3.3.5 arrange()\nThis one is pretty straightforward, it arranges the order of data in a column based on the values in the rows.\n\n# arrange the data in descend order by carat size\ndiamonds |&gt; \n  arrange(desc(carat))\n\n# I can resolve ties by including a second statement, 3.01 has lots of ties\ndiamonds |&gt; \n  filter(carat  &lt; 3.02) |&gt; \n  arrange(desc(carat), desc(cut))",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "data_wrangle.html#functions-for-summarizing",
    "href": "data_wrangle.html#functions-for-summarizing",
    "title": "3  Data Wrangling",
    "section": "3.4 Functions for Summarizing",
    "text": "3.4 Functions for Summarizing\n\n3.4.1 group_by()\ngroup_by() creates a “grouped table where all operations you perform are now done by the group you indicate.\nI wonder how many diamonds of each cut there are.\n\ndiamonds |&gt; \n  group_by(cut) |&gt; \n  count()\n\n# when count is used outside of a grouped table it just tells me the number of cases\ndiamonds |&gt; \n  count()\n\n\n\n3.4.2 summarise()\nsummarise() is used in conjunction with group_by() and we can use it to compare groups - super handy for t tests and ANOVAs. It collapses each group into a single row and treats each row as a case. Notice the new dataframe produced after summarize, it is much smaller.\nI’ve heard it’s tough to have big diamonds that are of high quality. So let’s find out.\n\ndiamonds |&gt;\n  group_by(cut) |&gt; \n  summarise(avg_carat = mean(carat)) # create new variable to compare groups\n\n# super useful for making graphs\ndiamonds |&gt;\n  group_by(cut) |&gt; \n  summarise(avg_carat = mean(carat)) |&gt; \n  ggplot(aes(x = cut, y = avg_carat)) + # ggplot only uses + \n  geom_col()\n\n# multiple calculations\ndiamonds |&gt;\n  group_by(cut) |&gt; \n  summarise(avg_carat = mean(carat), \n            n = n()) # can do multiple summarise arguments",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Data Wrangling</span>"
    ]
  },
  {
    "objectID": "data_viz.html",
    "href": "data_viz.html",
    "title": "4  Data Visualization",
    "section": "",
    "text": "4.1 ggplot\nData visualization is a critical component of research and data science. It is used for many things like data exploration, testing assumptions, and communicating findings. There are many packages that visualize data in R (and base R), but we will focus on the most common ggplot\nggplot is part of the tidyverse, it is widely used and highly customizable. However, it has it’s own rules and conventions that must be learned before making any graphs.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "data_viz.html#ggplot",
    "href": "data_viz.html#ggplot",
    "title": "4  Data Visualization",
    "section": "",
    "text": "4.1.1 syntax\nFirst, load in the tidyverse package and create a data object to work with.\n\nlibrary(tidyverse)\n\ndat &lt;- tibble(score = rnorm(100, mean = 5, sd = 1))\n\nWhen making a graph the first function will always be ggplot(). The first argument of ggplot, similar to the dplyr functions, is the data frame object we are working with. If we utilize the pipe we can write the code this way.\n\ndat %&gt;% \n  ggplot(arg_1 = whatever, \n         arg2 = whatever)\n\nThe second argument is aes() or aesthetics. This is where we assign values to various characteristics of the graph, like the x and y axes, fill, color, shape, linewidth, size, and linetype. Refer to the cheat sheet in the help menu for more information.\nYou do not have to choose values for all of these characteristics, only the ones necessary for the type of visualization you are creating. For example, when making a simple histogram we only need to assign a value to the x axis. So, the argument would look like this.\n\nggplot(dat, aes( x = score))\n\nThe part of ggplot most different from other code is how it handles moving from one function to the next. Normally, if we are working within the same data object we string together functions with the pipe. However, the pipe doesn’t work within ggplot, instead we have to use the plus sign +.\nAfter we set the aesthetic options we add our first layer to the visualization using a geom function. There are many geoms to work with, if you type geom R will suggest many for you. Let’s make a histogram.\n\ndat %&gt;% \n  ggplot(aes(x = score)) + \n  geom_histogram()\n\n\n\n\n\n\n\n\nGorgeous, let’s customize it a little.\n\n\n4.1.2 Title, subtitles, themes\nA simple way to add titles and subtitles to your graph is with the labs() function. It is added to your code with another plus sign like below. All text strings must be in quotations or else R will interpret them as objects.\n\ndat %&gt;% \n  ggplot(aes(x = score)) + \n  geom_histogram() + \n  labs(x = \"Psychology Score\", \n       title = \"Histogram of Psychology Scores\", \n       subtitle = \"A gorgeous visual\", \n       caption = \"Warning: there may be too much majesty in this frequency distribution\")\n\n\n\n\n\n\n\n\nAs we can see, these graphs are highly customizeable, but the caption at the bottom is probably overkill.\nAnother easy way to improve these graphs is by using themes. by using the theme() function. Again, there are many options to choose from.\n\ndat %&gt;% \n  ggplot(aes(x = score)) + \n  geom_histogram() + \n  labs(x = \"Psychology Score\", \n       title = \"Histogram of Psychology Scores\", \n       subtitle = \"A gorgeous visual\", \n       caption = \"Warning: there may be too much majesty in this frequency distribution\") + \n  theme_classic()\n\n\n\n\n\n\n\n\nWe can save this plot to an object using the assignment operator which allows us to manipulate it a little more. For example, with the help of the patchwork package we can easily manipulate the arrangement of multiple graphs.\n\n x &lt;- dat %&gt;% \n  ggplot(aes(x = score)) + \n  geom_histogram() + \n  labs(x = \"Psychology Score\", \n       title = \"Histogram of Psychology Scores\", \n       subtitle = \"A gorgeous visual\", \n       caption = \"Warning: there may be too much majesty in this frequency distribution\") + \n  theme_classic() \n \n y &lt;- dat %&gt;% \n  ggplot(aes(y = score)) + \n  geom_histogram(fill = \"lightblue\", color = \"darkblue\") + \n  labs(y = \"Psychology Score\", \n       title = \"Histogram of Psychology Scores\", \n       subtitle = \"A gorgeous visual\", \n       caption = \"Warning: there may be too much majesty in this frequency distribution\") + \n  theme_classic()\n \n library(patchwork)\n x + y\n\n\n\n\n\n\n\n x/y\n\n\n\n\n\n\n\n\n### adding layers\nGgplot creates graphs by adding a series of layers on top of one another. So, we can add a density curve to this histogram to make it look cool. MAY AS WELL ADD A VERTICAL LINE FOR THE MEAN WHILE WE’RE T IT.\nYou’ll notice I changed a lot of things, that’s ok, play around of check out the ggplot cheat sheet for things to change. The alpha value changes the transparency of the layer. We had to lower it because the curve is placed on top of the histogram.\n\n dat %&gt;% \n  ggplot(aes(x = score)) + \n  geom_histogram(aes(y = after_stat(density)), fill = \"white\", color = \"black\") + \n   geom_density(color = \"red\", fill = \"pink\", alpha = .3) + \n   geom_vline(xintercept = mean(dat$score), \n             color = \"black\", \n             linetype = \"dashed\", \n             linewidth = .75) + \n  labs(x = \"Psychology Score\", \n       title = \"Histogram of Psychology Scores\", \n       subtitle = \"A gorgeous visual\", \n       caption = \"Warning: there may be too much majesty in this frequency distribution\") + \n  theme_classic() \n\n`stat_bin()` using `bins = 30`. Pick better value `binwidth`.",
    "crumbs": [
      "Introduction to R",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "what_are_beh_sci.html",
    "href": "what_are_beh_sci.html",
    "title": "5  What are Behavioral Sciences",
    "section": "",
    "text": "5.1 What is Psychology?\nPsychology is the study of behavior and mental processes.\nPsychology is rooted in philosophical thought and exploration.\nWilhelm Wundt created the first psychology lab.\nYour Lineage:\nWundt -&gt; Titchener -&gt; Boring -&gt; Tulving -&gt; Habib -&gt; Me-&gt;You\nBehavioral research is involved in a multitude of different disciplines; like Social work, Criminology, and Communication.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are Behavioral Sciences</span>"
    ]
  },
  {
    "objectID": "what_are_beh_sci.html#goals-of-behavioral-research",
    "href": "what_are_beh_sci.html#goals-of-behavioral-research",
    "title": "5  What are Behavioral Sciences",
    "section": "5.2 Goals of Behavioral Research",
    "text": "5.2 Goals of Behavioral Research\nDescribe\nPatterns of behavior, thought, and emotion.\nPredict behavior\nFocus on developing equations that predict behavior.\nExplain behavior\nDevelop theoretical explanations for patterns of behavior.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are Behavioral Sciences</span>"
    ]
  },
  {
    "objectID": "what_are_beh_sci.html#two-schools-of-research",
    "href": "what_are_beh_sci.html#two-schools-of-research",
    "title": "5  What are Behavioral Sciences",
    "section": "5.3 Two Schools of Research",
    "text": "5.3 Two Schools of Research\nBasic Research\nResearch conducted without regard for whether the knowledge is immediately applicable\nEx. Does drinking coffee influence long-term memory?\nApplied Research\nResearch conducted to find solutions for problems rather than to enhance general knowledge\nEx. Does giving paid maternal/paternal leave increase employee happiness at USI?",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are Behavioral Sciences</span>"
    ]
  },
  {
    "objectID": "what_are_beh_sci.html#scientific-approach",
    "href": "what_are_beh_sci.html#scientific-approach",
    "title": "5  What are Behavioral Sciences",
    "section": "5.4 Scientific Approach",
    "text": "5.4 Scientific Approach\nSystematic Empiricism\nObserving behavior with clear guidelines for the purpose of drawing conclusions.\nPublic Verification\nAllows others to replicate and discuss your findings.\nSolvable Problems\nResearch questions must be solvable with the current technology.\nExamples of currently unsolvable problems: Whether Freud’s “unconscious” exists, angels, souls, quantum theory?, vampires, fairies",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are Behavioral Sciences</span>"
    ]
  },
  {
    "objectID": "what_are_beh_sci.html#purpose-of-behavioral-research",
    "href": "what_are_beh_sci.html#purpose-of-behavioral-research",
    "title": "5  What are Behavioral Sciences",
    "section": "5.5 Purpose of Behavioral Research",
    "text": "5.5 Purpose of Behavioral Research\nDetect\nDiscover and document new phenomena.\nExplain\nDevelop and evaluate theories that explain phenomena.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are Behavioral Sciences</span>"
    ]
  },
  {
    "objectID": "what_are_beh_sci.html#how-to-explain",
    "href": "what_are_beh_sci.html#how-to-explain",
    "title": "5  What are Behavioral Sciences",
    "section": "5.6 How to Explain",
    "text": "5.6 How to Explain\nTheory\nDescribes relationships between ideas.\nEx. Theory of Multiple Intelligences- Gardner suggests that there are 8-10 distinct modalities of intelligence instead of one general factor.\nExample: Theory of Evolution\nModel\nA representation of a process.\nExample: Assortative Mating Model-People tend to marry a partner who is has similar interests, lives close, makes a similar amount of money.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are Behavioral Sciences</span>"
    ]
  },
  {
    "objectID": "what_are_beh_sci.html#how-to-create-a-hypothesis",
    "href": "what_are_beh_sci.html#how-to-create-a-hypothesis",
    "title": "5  What are Behavioral Sciences",
    "section": "5.7 How to create a hypothesis",
    "text": "5.7 How to create a hypothesis\nHypothesis\nAn idea suggested as a way to explain a phenomena.\nPost-hoc\nExplanations made after the fact.\nA priori\nPredictions made before experimentation.\nAll hypotheses must be falsifiable, able to be unsupported, or shown to be false.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are Behavioral Sciences</span>"
    ]
  },
  {
    "objectID": "what_are_beh_sci.html#what-is-a-variable",
    "href": "what_are_beh_sci.html#what-is-a-variable",
    "title": "5  What are Behavioral Sciences",
    "section": "5.8 What is a variable?",
    "text": "5.8 What is a variable?\nA variable is something that you measure.\nTwo ways to define variables:\nConceptual definition\nA dictionary definition.\nEx: Drunk = affected by alcohol to the extent of losing control of one’s faculties or behavior.\nOperational definition\nDefinition that specifies precisely how a concept is measured, think about behaviors you can see.\nEx. Drunk = Blood Alcohol Content over .08.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are Behavioral Sciences</span>"
    ]
  },
  {
    "objectID": "what_are_beh_sci.html#proof-disproof-and-progress",
    "href": "what_are_beh_sci.html#proof-disproof-and-progress",
    "title": "5  What are Behavioral Sciences",
    "section": "5.9 Proof, Disproof, and Progress",
    "text": "5.9 Proof, Disproof, and Progress\nScientists do not prove anything, they find information that supports hypotheses.\nScientists may disprove.\nExample: How would one disprove the statement “Unicorns do not exist.”? They would find a unicorn.\nScientific progress depends on replication and accumulated evidence.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are Behavioral Sciences</span>"
    ]
  },
  {
    "objectID": "what_are_beh_sci.html#research-strategies",
    "href": "what_are_beh_sci.html#research-strategies",
    "title": "5  What are Behavioral Sciences",
    "section": "5.10 Research Strategies",
    "text": "5.10 Research Strategies\nDescriptive\nDescribes behavior, thoughts, or feelings.\nCorrelational\nInvestigates relationship between two or more variables.\nQuasi-experimental\nExamines naturally occurring variables.\nExperimental\nDetermines whether certain variables cause changes.\nNon-human animals can be studied in controlled conditions, for extended periods of time, and can be utilized in many types of research inappropriate for human beings.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>What are Behavioral Sciences</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html",
    "href": "how_plan_exp.html",
    "title": "6  How to plan an experiment",
    "section": "",
    "text": "6.1 Experimental Research\nAllows us to study causes of behavior.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#three-components-of-experimental-research",
    "href": "how_plan_exp.html#three-components-of-experimental-research",
    "title": "6  How to plan an experiment",
    "section": "6.2 Three components of Experimental Research",
    "text": "6.2 Three components of Experimental Research\n\nManipulate a variable\n\nExercise experimental control\n\nSystematically put participants in groups\n\nEnsure equivalent groups\n\nControl extraneous variables\n\nMake sure factors that are unimportant don’t influence results",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#independent-variable-iv",
    "href": "how_plan_exp.html#independent-variable-iv",
    "title": "6  How to plan an experiment",
    "section": "6.3 Independent variable (IV)",
    "text": "6.3 Independent variable (IV)\nThe variable that the researcher manipulates. All experimental research must have AT LEAST one. Researchers can manipulate the environment, the instructions, or they may use an invasive variable (like giving someone a caffeine pill).\nMust have at least 2 levels\nEx. Temperature may have two levels; hot and cold",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#subject-participant-variables",
    "href": "how_plan_exp.html#subject-participant-variables",
    "title": "6  How to plan an experiment",
    "section": "6.4 Subject (Participant) Variables",
    "text": "6.4 Subject (Participant) Variables\nBased off of a personal characteristic. Something you cannot manipulate in the lab.\nEx. Ethnicity/Race, Hobbies",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#evaluating-your-independent-variable",
    "href": "how_plan_exp.html#evaluating-your-independent-variable",
    "title": "6  How to plan an experiment",
    "section": "6.5 Evaluating Your Independent Variable",
    "text": "6.5 Evaluating Your Independent Variable\nA bad independent variable can result in a failed experiment.\nPilot Study\nTest your experiment on a small group of people to ensure that it works.\nManipulation Check\nDone to ensure that the level of your IV manipulation is strong enough.\nEx. Is 5mg of caffeine enough or should I use 10mg?",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#dependent-variable",
    "href": "how_plan_exp.html#dependent-variable",
    "title": "6  How to plan an experiment",
    "section": "6.6 Dependent Variable",
    "text": "6.6 Dependent Variable\nThe variable a researcher measures.\nExperiments must have AT LEAST one.\nEx. Heart rate, response to questionnaire, performance on test",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#groups-in-an-experiment",
    "href": "how_plan_exp.html#groups-in-an-experiment",
    "title": "6  How to plan an experiment",
    "section": "6.7 Groups in an Experiment",
    "text": "6.7 Groups in an Experiment\nExperimental\nThe group that receives the independent variable manipulation.\nEx. In a study about sleep, this group is required to stay awake for 2 days.\nControl\nThe group that is not exposed to any independent variable manipulation.\nEx. In the same sleep study, this group sleeps however much they usually sleep.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#assigning-participants",
    "href": "how_plan_exp.html#assigning-participants",
    "title": "6  How to plan an experiment",
    "section": "6.8 Assigning Participants",
    "text": "6.8 Assigning Participants\nSimple Random Assignment\nEveryone has an equal chance of being assigned to any group/condition.\nEx. Roll dice\nIn this situation people with any attribute are equally likely to be in either group.\nMatched Random Assignment\nParticipants are matched into homogeneous blocks. Participants in each block are then randomly assigned to conditions.\nIn this situation conditions will be similar along specific dimensions.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#within-subject-designs-repeated-measures",
    "href": "how_plan_exp.html#within-subject-designs-repeated-measures",
    "title": "6  How to plan an experiment",
    "section": "6.9 Within Subject Designs (repeated measures)",
    "text": "6.9 Within Subject Designs (repeated measures)\nParticipants are exposed to ALL conditions in an experiment.\nNo need for random assignment.\nEx. In an experiment testing a new drug all participants receive all doses of the drug (5mg, 10mg, 15mg)\nPros\nMore powerful\nCons\nOrder Effects",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#power",
    "href": "how_plan_exp.html#power",
    "title": "6  How to plan an experiment",
    "section": "6.10 Power",
    "text": "6.10 Power\nThe ability to detect IV effects.\nRequires fewer participants.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#order-effects",
    "href": "how_plan_exp.html#order-effects",
    "title": "6  How to plan an experiment",
    "section": "6.11 Order Effects",
    "text": "6.11 Order Effects\nCarryover effects\nOne condition influences the following condition.\nPractice effects\nParticipants have learned how to perform from previous experimental trials.\nFatigue effects\nParticipants are tired, bored, have no energy over time.\nSensitization\nParticipants realize the hypothesis being tested and do not perform naturally.\nCounterbalancing\ncan be used to correct for order effects.\nA researcher presents the levels of the IV in different orders for different participants.\n\n6.11.1 Between-Subjects Design (Independent Measures)\nParticipants experience only one condition of the IV.\nTypically requires random assignment.\nEx. In an experiment testing a new drug each participant will receive only one of the three levels of drug dosage (5mg or 10 mg or 15 mg).",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#experimental-control",
    "href": "how_plan_exp.html#experimental-control",
    "title": "6  How to plan an experiment",
    "section": "6.12 Experimental Control",
    "text": "6.12 Experimental Control\nTreatment effect\nSystematic differences due to the IV\nConfounds\nVariable other than the IV that differs systematically between conditions.\nConfounds invalidate your experiment because, if confounds are present, it is unclear whether the observed differences are due to the IV or the confound.\nMust be eliminated to draw accurate conclusions.\nError\nUnsystematic effects due to extraneous (uncontrolled) variables.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#sources-of-error",
    "href": "how_plan_exp.html#sources-of-error",
    "title": "6  How to plan an experiment",
    "section": "6.13 Sources of Error",
    "text": "6.13 Sources of Error\nIndividual Differences\nTransient states\nEnvironmental factors\nDifferential treatment\nMeasurement error",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#types-of-validity",
    "href": "how_plan_exp.html#types-of-validity",
    "title": "6  How to plan an experiment",
    "section": "6.14 Types of Validity",
    "text": "6.14 Types of Validity\nInternal Validity\nDegree to which we can draw accurate conclusions about the effects of the IV\nGain internal validity when all confounds are eliminated and you can conclude that the observed differences were due to the IV.\nHas experimental control.\nExternal Validity\nInverse relationship with internal validity\nThe greater experimental control in your experiment, the less likely it will be externally valid or generalizable to the “real world”.\nInternal validity is more critical and desirable than external validity. If you are not confident in the outcome of your experiment what value does it have?",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "how_plan_exp.html#threats-to-internal-validity",
    "href": "how_plan_exp.html#threats-to-internal-validity",
    "title": "6  How to plan an experiment",
    "section": "6.15 Threats to internal validity",
    "text": "6.15 Threats to internal validity\nBiased assignment of participants\nOccurs when random assignment isn’t possible or doesn’t produce equivalent groups.\nDifferential attrition\nParticipants drop out of the experiment differently across levels of the IV.\nDemand Characteristics\nParticipants perform in the way they believe the experimenter wants them to.\nPlacebo Effects\nChange as the result of the mere suggestion of change.\nPretest sensitization\nExposure to pretest affects one IV level differently than another\nHistory\nExternal events that participants experience affect one level of the IV differently than another\nExperimenter expectancy effects\nExperimenter with certain expectations interacts with participants differently\n\n6.15.1 Reducing threats to validity\nDouble Blind Procedure\nThe researcher administering the IV and the participant both do not know what level of the IV is being administered.\nCan eliminate expectancy effects and demand characteristics",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>How to plan an experiment</span>"
    ]
  },
  {
    "objectID": "measure_behav.html",
    "href": "measure_behav.html",
    "title": "7  Measuring behavior",
    "section": "",
    "text": "7.1 Types",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Measuring behavior</span>"
    ]
  },
  {
    "objectID": "measure_behav.html#types",
    "href": "measure_behav.html#types",
    "title": "7  Measuring behavior",
    "section": "",
    "text": "Observational\nPhysiological\nSelf-report",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Measuring behavior</span>"
    ]
  },
  {
    "objectID": "measure_behav.html#scales-of-measurement",
    "href": "measure_behav.html#scales-of-measurement",
    "title": "7  Measuring behavior",
    "section": "7.2 Scales of Measurement",
    "text": "7.2 Scales of Measurement\n\n7.2.1 Nominal Scales\nNumbers are assigned as labels for characteristics or behaviors.\nProvides the least amount of information.\nEx. Jersey Number\n\n\n7.2.2 Ordinal Scale\nRank ordering of people’s behaviors or characteristics.\nDoesn’t specify the distance between participants on the variable being measured.\nEx. Sizes at a fast food restaurant: baby, small, medium, large, ex large, super size, super duper size\n\n\n7.2.3 Interval Scale\nEqual distance between the numbers reflect equal differences between participants\nDoes not have a “true” zero point\nEx. Temperature, IQ score\n\n\n7.2.4 Ratio Scale\nHas a “true” zero point.\nProvides greatest amount of information.\nShould be used when possible.\nex. duration, weight, accuracy",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Measuring behavior</span>"
    ]
  },
  {
    "objectID": "measure_behav.html#central-tendency",
    "href": "measure_behav.html#central-tendency",
    "title": "7  Measuring behavior",
    "section": "7.3 Central Tendency",
    "text": "7.3 Central Tendency\nA descriptive measure which represents the entire distribution of scores (mean, median, mode).\nGoal: Find a single value that is representative of all the data.\nCan condense large data set into a single value.\nAllows comparison of 2 or more data sets using the central tendency.\n\n7.3.1 The Mean\nMost commonly used measure of central tendency.\nUsed in interval or ratio scales.\nIs influenced by extreme scores (outliers)\n\n7.3.1.1 How to compute:\nCompute the sum of all scores (∑)\nDivide the sum by the number of scores.\nIn manuscripts, the sample mean is identified as “M”\nThe sum (∑) of all scores (X) = (∑X)\n4 + 5 + 3 = 12\nDivide the sum by the number of scores (N) = (∑X/N)\n12/3 = 4\n\n\n7.3.1.2 Compute in R\nYou can calculate the mean in R with the function mean()\n\n# create vector of scores\nx &lt;- c(4, 5, 3)\n\n# use the mean function on the object\nmean(x)\n\n[1] 4\n\n\nThe mean is influenced by extreme scores. It gets pulled in the direction of the extreme score, making it less representative of the whole dataset and more reflective of the outlier (which isn’t what we want).\n\n# create vector of scores with an outlier\nx &lt;- c(4, 5, 3, 46)\n\n# use the mean function on the object\nmean(x)\n\n[1] 14.5\n\n\nThis score is not very reflective of our dataset, so we should use an alternative measure of central tendency, like the median.\nWeekly high temperatures in Chicago last winter:\n29, 31, 28, 32, 29, 27, 55\nWhat was the average high temperature in Chicago last winter?\nAll distances below the mean are equal to all the distances above the mean.\nChanging any score (adding or subtracting) will influence the mean.\n\n\n7.3.1.3 When you shouldn’t use the mean\nThe mean is not appropriate for nominal or ordinal scales.\n\nIt is impossible to calculate.\n\nThe mean is not appropriate when you have extreme scores (outliers).\n\nThe mean will be pulled towards the extreme score, rendering it no longer representative of the rest of the data.\n\nThe mean is not appropriate when there is missing data\n\n\n\n7.3.2 The Median\nScores are listed in order from smallest to largest\nThe median is the midpoint, it equally divides the scores\nWhen you have an even number of scores you take the average of the two middle scores.\nThe median can be used on ordinal, interval, or ratio scales.\nThe median is unaffected by extreme scores (outliers).\n\n# create vector of data \nx &lt;- c(1, 2, 3, 4, 5, 6, 7, 8, 9)\n\n# calculate median of the data object x\nmedian(x)\n\n[1] 5\n\n\nRemember the datset with an outlier from before? How does the median handle the outlier?\n\n# create vector of scores with an outlier\nx &lt;- c(4, 5, 3, 46)\n\n# use the median function on the object\nmedian(x)\n\n[1] 4.5\n\n\nThat is a much more representative measure for the entire dataset.\nWeekly high temperatures in Chicago last winter:\n29, 31, 28, 32, 29, 27, 55\nWhat was the median temperature in Chicago last winter?\n\n\n7.3.3 The Mode\nThe most frequently occurring score.\nCan be used on ALL scales of measurement.\nWeekly high temperatures in Chicago last winter:\n29, 31, 28, 32, 29, 27, 55\nWhat was the mode temperature in Chicago last winter?",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Measuring behavior</span>"
    ]
  },
  {
    "objectID": "measurement.html",
    "href": "measurement.html",
    "title": "8  Measurement",
    "section": "",
    "text": "8.1 Measurement\nMeasurement Error\nVariability in scores due to factors that distort the true score.\nTrue Score\nThe score a participant would obtain if a measure were perfect and we could measure without error.\nMeasurement error + True Score = Observed score",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Measurement</span>"
    ]
  },
  {
    "objectID": "measurement.html#sources-of-measurement-error",
    "href": "measurement.html#sources-of-measurement-error",
    "title": "8  Measurement",
    "section": "8.2 Sources of Measurement Error",
    "text": "8.2 Sources of Measurement Error\nTransient States\nTemporary state\nEx. mood\nStable Attribute\nA lasting state\nEx. Ambitious personality\nSituational factor\nResearch setting (Ex. Noise/temperature in the room)\nCharacteristics of the measure\nThe measure itself is ambiguous or too long\nMistakes in recording\nIncorrect data",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Measurement</span>"
    ]
  },
  {
    "objectID": "measurement.html#reliability",
    "href": "measurement.html#reliability",
    "title": "8  Measurement",
    "section": "8.3 Reliability",
    "text": "8.3 Reliability\nConsistency/dependability of the measuring technique\nInverse relationship with measurement error\nIf observed score is close to the true score, your measure has high reliability\nCan be assessed using several measurements of the same behavior and comparing to see if they resulted in similar scores (typically through a correlation)\nCorrelation Coefficient\nValue that describes relationship between two measures\nRanges from -1.00 to +1.00, sign indicates direction\nCorrelation of .00 indicates no relationship",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Measurement</span>"
    ]
  },
  {
    "objectID": "measurement.html#forms-of-reliability",
    "href": "measurement.html#forms-of-reliability",
    "title": "8  Measurement",
    "section": "8.4 Forms of Reliability",
    "text": "8.4 Forms of Reliability\nInter-rater Reliability\nConsistency among two or more researchers who observe and record participants’ behavior\nTest-Retest Reliability\nConsistency of responses on a measure over time, use the same measure twice and evaluate the correlation.\nThe results of a reliable measure should not change over time.\nInter-Item Reliability\nConsistency between items on a scale.\nTells the researcher whether the items on the scale are measuring the same thing\nIf the items do not measure the same thing, measurement error increases and reliability decreases.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Measurement</span>"
    ]
  },
  {
    "objectID": "measurement.html#indices-of-inter-item-reliability",
    "href": "measurement.html#indices-of-inter-item-reliability",
    "title": "8  Measurement",
    "section": "8.5 Indices of Inter-Item Reliability",
    "text": "8.5 Indices of Inter-Item Reliability\nItem-total correlation\nThe correlation between one item and the sum of all other items on a scale.\nSplit-half reliability\nDivide items on a scale into two sections and examine the correlation between the sections.\nCronbach’s Alpha (α)\nThe average of all possible split-half reliabilities\nMost frequently used\nα &gt; .70 considered acceptable",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Measurement</span>"
    ]
  },
  {
    "objectID": "measurement.html#increasing-reliability",
    "href": "measurement.html#increasing-reliability",
    "title": "8  Measurement",
    "section": "8.6 Increasing Reliability",
    "text": "8.6 Increasing Reliability\nStandardize how measure is administered\nClarify instructions and questions\nTrain researchers/coders\nMinimize errors in coding data",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Measurement</span>"
    ]
  },
  {
    "objectID": "measurement.html#validity",
    "href": "measurement.html#validity",
    "title": "8  Measurement",
    "section": "8.7 Validity",
    "text": "8.7 Validity\nHow accurate is a measure at estimating what it is attempting to assess?\nDo differences in scores truly reflect differences in what you are trying to measure?",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Measurement</span>"
    ]
  },
  {
    "objectID": "measurement.html#forms-of-validity",
    "href": "measurement.html#forms-of-validity",
    "title": "8  Measurement",
    "section": "8.8 Forms of Validity",
    "text": "8.8 Forms of Validity\nFace Validity\nThe extent to which an assessment appears to describe what it is supposed to measure.\nDoes not actually impact the “true” validity\nConstruct Validity\nHow well does a measurement of a hypothetical construct relate to other measures.\n\nHypothetical Construct\n\nSomething that cannot be directly observed, but is inferred based on observation or experience.\nEx. Personality, Confidence\n\n\nConvergent Validity\nA measure correlates with other measures that it should correlate with\nDiscriminant Validity\nA measure does not correlate with other measures that it should not correlate with",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Measurement</span>"
    ]
  },
  {
    "objectID": "measurement.html#bias",
    "href": "measurement.html#bias",
    "title": "8  Measurement",
    "section": "8.9 Bias",
    "text": "8.9 Bias\nTest Bias\nWhen the validity of a measure is lower for some groups than others.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Measurement</span>"
    ]
  },
  {
    "objectID": "variability.html",
    "href": "variability.html",
    "title": "9  Variability",
    "section": "",
    "text": "9.1 Variability\nNEED RAFALIB PACKAGE\nA quantitative measure of difference between a set of scores that describes how scores are scattered around a central point.\nDescriptive Variability\nAssesses spread or clustering of scores.\nInferential Variability\nAssesses how accurately one individual score/sample represents the population.\nUsed to detect patterns, variability influences how easily those patterns are detected.\nVariability can be small or large.\nSmall indicates that scores are very clustered together.\nLarge indicates that scores are widely dispersed.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variability</span>"
    ]
  },
  {
    "objectID": "variability.html#measures-of-variability",
    "href": "variability.html#measures-of-variability",
    "title": "9  Variability",
    "section": "9.2 Measures of Variability",
    "text": "9.2 Measures of Variability\n\n9.2.1 Range\nTotal distance covered by the distribution, from highest to lowest value, also gives information about how many categories there are.\nRelies on two values (extremes), ignores all others\nRange = Maximum Score – Minimum Score\n\n9.2.1.1 Calculate in R\nLet’s use R to work out an example. First, use the sample function to create 10 scores from 1:10 and assign that list of numbers (called a vector) to the object ‘x’.\n\n# random sample of 10 scores from 1-10\nx &lt;- sample(1:10, 10)\n\nThe range function will produce the two values we use to calculate the range, the highest and lowest.\n\n# gives us the extreme values\nrange(x)\n\nThe max and min function will give us the largest and smallest numbers respectively.\n\n# gives us the maximum value\nmax(x)\n\n# gives us the minimum value\nmin(x)\n\nNow we can use these functions to calculate the range.\n\nmax(x) - min(x)\n\n\n\n\n9.2.2 Variance & Standard Deviation\nCalculated using all scores in a distribution\nMost commonly used measure of variability\nDescribes average distance between a score and the mean\nUsed with interval and ratio scales\nvariance definition of variance\nstandard deviation definition of standard deviation\n\n9.2.2.1 Calculate by hand\n\nCalculate the mean.\nSubtract the mean from each individual score to get a difference score for each participant. Make sure that if you add all of the difference scores they equal zero.\nSquare the difference scores to get squared scores.\nAdd all of the squared scores to get the Sum of Squared Deviations (SS).\nDivide the SS by the size of your population (N) or sample (n-1) to get the variance (σ2 or s2).\nFind the square root of σ2 to find the standard deviation(σ or s).\n\n\n\n9.2.2.2 Calculate in R (long)\nStart with a simple vector we will store in the object ‘y’.\n\n# data\ny &lt;- c( 1, 2, 3, 4, 5)\n\n\nCalculate the mean.\n\n\nmean(y)\n\n[1] 3\n\n\n\nSubtract the mean from each individual score to get a difference score for each participant. Make sure that if you add all of the difference scores they equal zero.\n\n\ndiff_score &lt;- y - mean(y)\n\n\nSquare the difference scores to get squared scores.\n\n\nsq_score &lt;- diff_score^2\n\n\nAdd all of the squared scores to get the Sum of Squared Deviations (SS).\n\n\nSS &lt;- sum(sq_score)\n\n\nDivide the SS by the size of your population (N) or sample (n-1) to get the variance (σ^2 or s^2).\n\n\n# variance for a population\npop_var &lt;- SS/length(y)\npop_var\n\n[1] 2\n\n# variance for a sample \nsample_var &lt;- SS/(length(y) - 1)\nsample_var\n\n[1] 2.5\n\n\n\nFind the square root of σ2 to find the standard deviation(σ or s).\n\n\n# population standard deviation\nsqrt(pop_var)\n\n[1] 1.414214\n\n# sample standard deviation\nsqrt(sample_var)\n\n[1] 1.581139\n\n\n\n\n9.2.2.3 Calculate in R (short)\nStart with the same data\n\n# data\ny &lt;- c( 1, 2, 3, 4, 5)\n\n\nCalculate variance. For the calculation of population variance and standard deviation we can use the rafalib package. For populations we will use the popvar function and for sample vaiance we will use the var function from base R.\n\n\n# population variance\nlibrary(rafalib)\npopvar(y)\n\n[1] 2\n\n# sample variance\nvar(y)\n\n[1] 2.5\n\n\n\nCalculate standard deviation\n\n\n# population stabdard deviation\npopsd(y)\n\n[1] 1.414214\n\n# sample sd\nsd(y)\n\n[1] 1.581139",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variability</span>"
    ]
  },
  {
    "objectID": "variability.html#population-v-sample",
    "href": "variability.html#population-v-sample",
    "title": "9  Variability",
    "section": "9.3 Population v Sample",
    "text": "9.3 Population v Sample\nPopulation is EVERYONE.\nVariance (σ2) = SS/N\nStandard Deviation (σ) = √(SS/N)\nSample is a subset of everyone.\nVariance (s2) = SS/n-1.\nStandard Deviation (s) = √(SS/(n-1)).\nWe use a different formula for samples because we are using limited information from a small group (the sample) to draw inferences about a larger group (the population).\nSamples have less variability than populations, so statistics we run on them must be adjusted to account for this.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variability</span>"
    ]
  },
  {
    "objectID": "variability.html#biased-and-unbiased-statistics",
    "href": "variability.html#biased-and-unbiased-statistics",
    "title": "9  Variability",
    "section": "9.4 Biased and Unbiased Statistics",
    "text": "9.4 Biased and Unbiased Statistics\nBiased Statistics\nThe average value calculated for a sample overestimates or underestimates the population parameter\ni.e. the sample before adjustment (n-1)\nUnbiased Statistics\nThe average value is equal to the population parameter.\ni.e. the sample after adjustment (n-1).",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variability</span>"
    ]
  },
  {
    "objectID": "variability.html#transforming-data-sets",
    "href": "variability.html#transforming-data-sets",
    "title": "9  Variability",
    "section": "9.5 Transforming Data Sets",
    "text": "9.5 Transforming Data Sets\n\n9.5.1 Adding a constant\nWhen you add a value to every score in the data set it does not change the standard deviation. Try it out calculate the sample standard deviation of the example_1.\n\nexample_1 &lt;- c(1, 2, 3, 4, 5)\n\ns &lt;- sd(example_1)\ns\n\n[1] 1.581139\n\n\nNow, let’s add a constant value of 2 to every score.\n\nexample_2 &lt;- example_1 + 2\nexample_2\n\n[1] 3 4 5 6 7\n\n\nLet’s see if the sample standard deviation changed.\n\ns &lt;- sd(example_2)\n\nThere is no difference because the distance between scores is unchanged. The shape of the distribution is the same, just shifted to the right.\n\n\n\n\n\n\n\n\n\n\n\n9.5.2 Multiplying by a constant\nMultiplying every score in the data set by a constant changes standard deviation. Try it out. Calculate the sample standard deviation of example_1.\n\nexample_1 &lt;- c(1, 2, 3, 4, 5)\n\ns &lt;- sd(example_1)\ns\n\n[1] 1.581139\n\n\nNow, let’s multiply every score by a constant of 3.\n\nexample_2 &lt;- example_1 * 3\nexample_2\n\n[1]  3  6  9 12 15\n\n\nLet’s see if the sample standard deviation has changed.\n\ns &lt;- sd(example_2)\ns\n\n[1] 4.743416\n\n\nThere distributions now look very different. The distance between scores in example_2 has changed by a multiple of 3. The distance between scores is now greater, resulting in a wider distribution.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Variability</span>"
    ]
  },
  {
    "objectID": "select_participants.html",
    "href": "select_participants.html",
    "title": "10  Selecting participants",
    "section": "",
    "text": "10.1 Sampling\nDifficult to study everyone (population)\nEx. Every single person with PTSD\nProbability Samples\nCan quantify the likelihood of being selected because we know how many people are in the population of interest\nKnow selection probability\nAccurately describes a population\nMust be representative of the population\nRarely used in behavioral sciences\nEx. A 1 in a million chance of winning the lottery\nNon-Probability\nCan’t quantify the likelihood of being selected, probably because we don’t know how many people are in the population being measured.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Selecting participants</span>"
    ]
  },
  {
    "objectID": "select_participants.html#error-of-estimation",
    "href": "select_participants.html#error-of-estimation",
    "title": "10  Selecting participants",
    "section": "10.2 Error of Estimation",
    "text": "10.2 Error of Estimation\nSamples rarely mirror the population perfectly\nThe difference between them is called sampling error\nSampling error can be estimated for probability samples because we know the population size",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Selecting participants</span>"
    ]
  },
  {
    "objectID": "select_participants.html#probability-sampling",
    "href": "select_participants.html#probability-sampling",
    "title": "10  Selecting participants",
    "section": "10.3 Probability sampling",
    "text": "10.3 Probability sampling",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Selecting participants</span>"
    ]
  },
  {
    "objectID": "select_participants.html#types-of-probability-sampling",
    "href": "select_participants.html#types-of-probability-sampling",
    "title": "10  Selecting participants",
    "section": "10.4 Types of Probability Sampling",
    "text": "10.4 Types of Probability Sampling\nSimple Random Sampling\nKnown Population\nRandom Selection\nEqual selection probability for every sample\nEx. Pulling a name out of a hat\nRequire a sampling frame\n\nAn outline of the people you will be sampling from\n\nex. USI students enrolled in Introduction to Psychology this year\nSystematic Sampling\nNot concerned with population size\nEvery nth person gets chosen\nIt is not random, a system is used to choose participants\nEx. The every third person who enters the classroom gets to participate in an experiment\nStratified Random Sampling\nDivide population into groups based on a shared characteristic (called strata)\nRandomly sample people from each strata\nThis sampling method ensures an adequate number of participants from each group\nEx. Separate participants into groups based on major, then take 5 random participants from those strata\nClustered Sampling\nClusters occur naturally\nSample the clusters, then sample participants\nMore efficient than stratified random sampling because only the clusters are sampled\nClusters are essentially the same as one another, whereas strata are fundamentally different\nEx. Randomly sample 5 of the counties in Illinois, then randomly sample the participants in those counties.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Selecting participants</span>"
    ]
  },
  {
    "objectID": "select_participants.html#issues-with-probability-sampling",
    "href": "select_participants.html#issues-with-probability-sampling",
    "title": "10  Selecting participants",
    "section": "10.5 Issues with Probability Sampling",
    "text": "10.5 Issues with Probability Sampling\nNon-response\nSome participants do not respond, these participants may be different in some important way from those that do respond\nMisgeneralization\nGeneralizing to the wrong population",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Selecting participants</span>"
    ]
  },
  {
    "objectID": "select_participants.html#non-probability-samples",
    "href": "select_participants.html#non-probability-samples",
    "title": "10  Selecting participants",
    "section": "10.6 Non-probability Samples",
    "text": "10.6 Non-probability Samples\nCan’t calculate selection probability\nNot random\nUsed to study relationships among variables\nBehavioral sciences use non-probability samples most often\n\n10.6.1 Types of Non-probability Samples\nConvenience Sampling\nUses participants that are easy to obtain\nMost typical type of non-probability sampling\nReplication of experiments shows generalizability\nQuota Sampling\nSpecific proportions of people with selected characteristics are selected\nOften used for market research\nEx: 20 USI students who enjoy hiking\nSnowball Sampling\nUsed for hard to reach groups\nCan use incentives (cautiously) to increase response\nEx: For every person you bring in to the experiment I will give you 5 dollars",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Selecting participants</span>"
    ]
  },
  {
    "objectID": "select_participants.html#how-many-participants-is-enough",
    "href": "select_participants.html#how-many-participants-is-enough",
    "title": "10  Selecting participants",
    "section": "10.7 How Many Participants is Enough?",
    "text": "10.7 How Many Participants is Enough?\nEconomic samples are typical, only collect as much data as needed.\nDetermine how many are needed via a power analysis.\nAim for reasonable accuracy and cost for the scope of the project.",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Selecting participants</span>"
    ]
  },
  {
    "objectID": "ethics.html",
    "href": "ethics.html",
    "title": "11  Ethical Issues in Behavioral Research",
    "section": "",
    "text": "11.1 Researcher Obligations\nEnhance Understanding\nProtect participants\nEthical questions arise when enhancing understanding and protecting participants conflict",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ethical Issues in Behavioral Research</span>"
    ]
  },
  {
    "objectID": "ethics.html#some-approaches-to-ethical-decisions",
    "href": "ethics.html#some-approaches-to-ethical-decisions",
    "title": "11  Ethical Issues in Behavioral Research",
    "section": "11.2 Some approaches to ethical decisions",
    "text": "11.2 Some approaches to ethical decisions\nDeontology\nEthical decisions are made based on a moral code\nUtilitarianism\nEthical decisions are made based on weighing the benefits and consequences\nEthical Skepticism\nBelief that a concrete moral code cannot exist\n\n11.2.1 Benefits of Utilitarianism\nBasic knowledge\nImproved techniques\nPractical outcomes\nBenefits for researchers\nBenefits for participants\n\n\n11.2.2 Costs of Utilitarianism\nTime and effort\nParticipant’s welfare\nMoney\nDeception; creating distrust",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ethical Issues in Behavioral Research</span>"
    ]
  },
  {
    "objectID": "ethics.html#institutional-review-board-irb",
    "href": "ethics.html#institutional-review-board-irb",
    "title": "11  Ethical Issues in Behavioral Research",
    "section": "11.3 Institutional Review Board (IRB)",
    "text": "11.3 Institutional Review Board (IRB)\nScientific and nonscientific board members\nResearchers describes purpose, procedures, and risks\nIRB must approve study before it can be conducted",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ethical Issues in Behavioral Research</span>"
    ]
  },
  {
    "objectID": "ethics.html#lack-of-adequate-informed-consent",
    "href": "ethics.html#lack-of-adequate-informed-consent",
    "title": "11  Ethical Issues in Behavioral Research",
    "section": "11.4 Lack of adequate informed consent",
    "text": "11.4 Lack of adequate informed consent\nInformed consent is a disclosing of the nature of participation\nA researcher must obtain explicit agreement from participants\nPossible problems:\nCompromise study validity\nSome participants are unable to consent",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ethical Issues in Behavioral Research</span>"
    ]
  },
  {
    "objectID": "ethics.html#ethical-considerations",
    "href": "ethics.html#ethical-considerations",
    "title": "11  Ethical Issues in Behavioral Research",
    "section": "11.5 Ethical Considerations",
    "text": "11.5 Ethical Considerations\n\n11.5.1 Invasion of privacy\nParticipants may decide when, where, to whom, and what responses to reveal\nPublic observation is not an invasion of privacy\n\n\n11.5.2 Coercion\nPressure to participate from an authority figure\nTo prevent coercion, alternate activity must be available to opt of out research\n\n\n11.5.3 Potential Harm\nPain, stress, failure, anxiety, or other negative emotions\nMinimal risk – no greater than that ordinarily encountered\nMore than minimal risk requires strong justification\n\n\n11.5.4 Deception\nFalse purpose of study\nExperimental Confederate\nFalse feedback\nPresenting related studies as unrelated\nGiving incorrect information regarding stimulus materials\n\n\n11.5.5 Violation of Confidentiality\nData may only be used for research\nData may not be disclosed to others\nAnonymity is the easiest way to ensure confidentiality\n\n\n11.5.6 Debriefing\nClarify nature of study\nRemove any stress or negative study-indices consequences\nObtain participant reactions\nEnsure participants leave feeling good about participation\n\n\n11.5.7 Vulnerable Populations\nChildren\nPrisoners\nPeople with impaired decision making\nPeople at risk for suicide\nPregnant women, fetuses, newborns\n\n\n11.5.8 Scientific Misconduct\nFabrication, falsification, plagiarism\nQuestionable research practices\nUnethical behavior",
    "crumbs": [
      "Research Methods",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Ethical Issues in Behavioral Research</span>"
    ]
  },
  {
    "objectID": "z_scores.html",
    "href": "z_scores.html",
    "title": "12  z scores",
    "section": "",
    "text": "12.1 z-scores\nRaw scores provide very little information by themselves\nEx. Terrence got 34 points on the test. Did he do well?\nWe have no idea - how many points were there? How did his peers perform?\nThe mean and standard deviation provide a context with which to interpret the raw score.\nEx. Terrence’s class average was 75 points with a 2 point standard deviation. His score of 34 is uniquely terrible.\nz-scores tell us where an x value is located in relation to the mean and standard deviation with one number - the z score.\nA z score is a signed (+ or -) number, like -1.5 or +2.\nThe sign tells you whether the x value is above the mean (positive) or below the mean (negative).\nThe number tells you the amount of standard deviations between the raw score and the mean of the distribution.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>z scores</span>"
    ]
  },
  {
    "objectID": "z_scores.html#z-scores-as-a-standardized-distribution",
    "href": "z_scores.html#z-scores-as-a-standardized-distribution",
    "title": "12  z scores",
    "section": "12.2 Z-scores as a Standardized Distribution",
    "text": "12.2 Z-scores as a Standardized Distribution\nz-scores do not change the shape of the original distribution or the location of a score relative to others.\nBecause the scores are standardized we can compare scores from two completely different scales. For example, if a biology exam was scored out of 100 points and a psychology exam was scored of 75 points we could compare our performance on them via z scores. The first observation in the dataset below got 60 points on both exams. However, the 60 on the psych exam is a “worse” score because everyone in the class did better.\n\n\n# A tibble: 7 × 4\n    bio   z_bio   psy  z_psy\n  &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt;\n1    60 -1.10      60 -1.73 \n2    78  0.0456    75  1.25 \n3    88  0.685     65 -0.739\n4    57 -1.30      70  0.256\n5    98  1.32      73  0.853\n6    70 -0.466     70  0.256\n7    90  0.812     68 -0.142\n\n\nWhen raw scores are transformed into z-scores, the resulting distribution:\n\nAlways has a mean of 0\nAlways has a standard deviation of 1\nMost z-scores are between z = -2.00 and z = +2.00",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>z scores</span>"
    ]
  },
  {
    "objectID": "z_scores.html#z-score-formula",
    "href": "z_scores.html#z-score-formula",
    "title": "12  z scores",
    "section": "12.3 Z-score Formula",
    "text": "12.3 Z-score Formula\n\n12.3.1 Samples\n(x - M) / s\n\n\n12.3.2 Populations\n(x - M )/ \\(\\sigma\\)",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>z scores</span>"
    ]
  },
  {
    "objectID": "z_scores.html#calculating-z-scores-in-r",
    "href": "z_scores.html#calculating-z-scores-in-r",
    "title": "12  z scores",
    "section": "12.4 Calculating z-scores in R",
    "text": "12.4 Calculating z-scores in R\nTo calculate a z score we will need to use the scale() function. First, we will create a vector of scores using the sample() function. When using the sample() function the first argument is the range of scores you are asking R to generate values from, then the size argument is how many observations you want, the final argument is replace. When replace = TRUE then the same number can appear twice. This is called sampling WITH replacement.\n\nlibrary(pacman) \np_load(rio, tidyverse, skimr) \n\n\nsample(min value:max value, size = number of observations, replace = TRUE)\n\nWhen combining sample() with the tibble() function to create a small dataframe our code looks like this.\n\nsmall &lt;- tibble(raw_scores = sample(1:10, size = 25, replace = TRUE))\nsmall\n\n# A tibble: 25 × 1\n   raw_scores\n        &lt;int&gt;\n 1          4\n 2          3\n 3         10\n 4          7\n 5          7\n 6          3\n 7         10\n 8          3\n 9          6\n10          1\n# ℹ 15 more rows\n\n\nNow that we have a set of raw scores, let’s transform them into z scores.\n\nsmall &lt;- small %&gt;% \n  mutate(z_scores = scale(raw_scores))\n\nsmall\n\n# A tibble: 25 × 2\n   raw_scores z_scores[,1]\n        &lt;int&gt;        &lt;dbl&gt;\n 1          4       -0.438\n 2          3       -0.780\n 3         10        1.61 \n 4          7        0.588\n 5          7        0.588\n 6          3       -0.780\n 7         10        1.61 \n 8          3       -0.780\n 9          6        0.246\n10          1       -1.46 \n# ℹ 15 more rows\n\n\nDid it work? Let’s check out a quick snapshot of our data with the skim() function. We can see that the mean for the z scores is incredibly close to zero. Good enough. We also see that the standard deviation is 1. That is what we’d expect.\n\nskim(small)",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>z scores</span>"
    ]
  },
  {
    "objectID": "z_scores.html#visualize",
    "href": "z_scores.html#visualize",
    "title": "12  z scores",
    "section": "12.5 Visualize",
    "text": "12.5 Visualize\n\nWhat do you notice when you compare the two distributions to one another?\nAre the x axes the same?\nAre the distributions the same shape?\n\n\nRaw score distributionZ score distribution\n\n\n\nsmall %&gt;% \n  ggplot(aes(x = raw_scores)) + \n  geom_histogram(bins = 10) + \n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nsmall %&gt;% \n  ggplot(aes(x = z_scores)) + \n  geom_histogram(bins = 10) + \n  theme_classic()",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>z scores</span>"
    ]
  },
  {
    "objectID": "z_scores.html#larger-datasets",
    "href": "z_scores.html#larger-datasets",
    "title": "12  z scores",
    "section": "12.6 Larger Datasets",
    "text": "12.6 Larger Datasets\nLet’s try with larger datasets, one where the data is randomly distributed and one where the data is normally distributed.\n\nrandom_dat &lt;- tibble(raw_scores =sample(1:100, size = 1000, replace = TRUE)) \n\nnorm_dat &lt;- tibble(raw_scores = rnorm(1000, mean = 100, sd = 10))\n\n\n12.6.1 find z for all scores in a dataset\n\n# create a column in the dataframe named \"z-score\" using scale function\n\nrandom_dat &lt;- random_dat |&gt; \n  mutate(z_score = scale(raw_scores))\n         \nnorm_dat &lt;- norm_dat |&gt; \n  mutate(z_score = scale(raw_scores))\n\n\n\n12.6.2 compare\nDespite very different raw values the mean for the z scores is zero and the standard deviation is 1.\n\nskim(random_dat)\nskim(norm_dat)\n\n\n\n12.6.3 Visualize raw scores\n\nrandomly distributednormally distributed\n\n\n\n# plot the raw score distribution\n\nrandom_dat %&gt;% \n  ggplot(aes(x = raw_scores)) + \n  geom_histogram(bins = 25) + \n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nnorm_dat %&gt;% \n  ggplot(aes(x = raw_scores)) + \n  geom_histogram(bins = 25) + \n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\n\n\n12.6.4 Visualize z scores\n\nrandomly distributednormally distributed\n\n\n\nrandom_dat %&gt;% \n  ggplot(aes(x = z_score)) +\n  geom_histogram(bins = 25) +\n  theme_classic()\n\n\n\n\n\n\n\n\n\n\n\nnorm_dat %&gt;% \n  ggplot(aes(x = z_score)) + \n  geom_histogram(bins = 25) + \n  theme_classic()",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>z scores</span>"
    ]
  },
  {
    "objectID": "z_scores.html#z-scores-and-probability",
    "href": "z_scores.html#z-scores-and-probability",
    "title": "12  z scores",
    "section": "12.7 z scores and probability",
    "text": "12.7 z scores and probability\nWe often need to know how likely it is to obtain a certain score. We can do this by using the pnorm() function. This function has four arguments we need to understand.\n\nq is the value that you want to calculate the probability of\nmean is the mean of the distribution\nsd is the standard deviation of the distribution\nlower.tail indicates whether we are looking at the lower tail or upper tail of the distribution. If it is FALSE, then we are looking at the upper tail.\n\nPsyTeachR - Data Skills Chapter 13 and 14 are great for this\nThis code gives us the probability of obtaining a z score smaller than -1.96. We know this is a z distribution because the mean is 0 and the standard deviation is 1.\n\npnorm(q = -1.96, mean = 0, sd = 1, lower.tail = TRUE)\n\n[1] 0.0249979\n\n\nThe probability value, or p, is &lt; .25\nThe code below gives us the probability of randomly selecting a score of 700 or above from a dataset with a mean of 500, and a standard deviation of 100.\n\npnorm(q = 700, mean = 500, sd = 100, lower.tail = FALSE)\n\n[1] 0.02275013",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>z scores</span>"
    ]
  },
  {
    "objectID": "z_scores.html#z-scores-and-locations",
    "href": "z_scores.html#z-scores-and-locations",
    "title": "12  z scores",
    "section": "12.8 Z-scores and Locations",
    "text": "12.8 Z-scores and Locations\nAs descriptive statistics, z scores describe exactly where a score is located in a distribution.\nAs inferential statistics, determine whether a sample is representative of its population.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>z scores</span>"
    ]
  },
  {
    "objectID": "probability.html",
    "href": "probability.html",
    "title": "13  Probability",
    "section": "",
    "text": "13.1 Probability\nThe likelihood of all possible outcomes\n“Probability” = p\nCan use fractions, decimals, or percentages:\np = ½ = .50 = 50%\nGoes from 0% - 100% or 0 – 1\nEquals the desired outcome divided by all possible outcomes",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "probability.html#probability-sampling",
    "href": "probability.html#probability-sampling",
    "title": "13  Probability",
    "section": "13.2 Probability & Sampling",
    "text": "13.2 Probability & Sampling\nSamples are used in inferential statistics, to make inferences about larger populations\nProbability can be used to quantify the relationship between samples and population\nWhen something occurs in a sample, how likely is it that it represents the population?\nProbability calculation requires independent random sampling, has an equal probability of being selected and replacement",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "probability.html#probability-and-inferential-statistics",
    "href": "probability.html#probability-and-inferential-statistics",
    "title": "13  Probability",
    "section": "13.3 Probability and Inferential Statistics",
    "text": "13.3 Probability and Inferential Statistics\nLow probability values = Special/Rare, not common or likely to happen\nHigh probability values = Common/likely to happen\nIn terms of finding an effect:\nLow probability = effect\nMeans your finding is unlikely to happen by chance, there is a different cause\nHigh probability = no effect\nMeans your finding is common or likely to happen",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "probability.html#probability-and-frequency-distributions",
    "href": "probability.html#probability-and-frequency-distributions",
    "title": "13  Probability",
    "section": "13.4 Probability and Frequency Distributions",
    "text": "13.4 Probability and Frequency Distributions\nIf a distribution displays a population of scores a portion of the graph represents a portion of the population\nProbability can be defined by a proportion of the graph\nCan determine this by using the z-score and the unit normal table",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Probability</span>"
    ]
  },
  {
    "objectID": "dist_sample_means.html",
    "href": "dist_sample_means.html",
    "title": "14  Distribution of Sample Means",
    "section": "",
    "text": "14.1 Samples vs. Populations\nThough most behavioral science uses samples to test hypotheses, those hypotheses are almost always about populations.\nA sample is not a perfect representation of a population, so any statistics you calculate for that sample are also not representative of the population. They are approximations.\nSampling Error\nThe difference between sample statistics and population parameters.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribution of Sample Means</span>"
    ]
  },
  {
    "objectID": "dist_sample_means.html#sampling-distributions",
    "href": "dist_sample_means.html#sampling-distributions",
    "title": "14  Distribution of Sample Means",
    "section": "14.2 Sampling Distributions",
    "text": "14.2 Sampling Distributions\nSampling Distribution\nA distribution of statistics of all possible samples of a given size from a population\nOne example of a sampling distribution is…..\nDistribution of Sample Means\nA collection of sample means for all possible random samples of a given size that could be obtained from a population.\nA distribution of sample means should form a normal distribution, with most of the sample means grouping around the population mean if the number of scores in each sample is more than 30.\nLarger samples are more representative of populations than smaller samples.\nThe mean of the distribution of sample means is the always same as the population mean.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribution of Sample Means</span>"
    ]
  },
  {
    "objectID": "dist_sample_means.html#standard-error-of-the-mean",
    "href": "dist_sample_means.html#standard-error-of-the-mean",
    "title": "14  Distribution of Sample Means",
    "section": "14.3 Standard Error of the Mean",
    "text": "14.3 Standard Error of the Mean\nThe standard deviation of the distribution of sample means is the\nStandard Error of the Mean\n𝜎𝑀= 𝜎𝑛√ 𝜎 M =\n𝜎 n",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribution of Sample Means</span>"
    ]
  },
  {
    "objectID": "dist_sample_means.html#z-score-for-a-sample",
    "href": "dist_sample_means.html#z-score-for-a-sample",
    "title": "14  Distribution of Sample Means",
    "section": "14.4 Z-score for a Sample",
    "text": "14.4 Z-score for a Sample\nBy using a sampling distribution you can calculate the location of an entire sample within a population\nz = M - µ\nσM\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 600\nlibrary(shiny)\nlibrary(bslib)\n\nui &lt;- page_sidebar(\n  title = \"Sampling Distribution Explorer\",\n  sidebar = sidebar(\n    sliderInput(\"n\", \"Sample Size (n):\", min = 2, max = 100, value = 30),\n    sliderInput(\"sims\", \"Number of Simulations:\", min = 5, max = 150, value = 1000, step = 5),\n    actionButton(\"resample\", \"Generate New Samples\", class = \"btn-primary\")\n  ),\n  card(\n    card_header(\"Distribution of Sample Means\"),\n    plotOutput(\"distPlot\")\n  )\n)\n\nserver &lt;- function(input, output, session) {\n  sample_means &lt;- reactive({\n    input$resample\n    # Simulate drawing random samples from a normal population\n    replicate(input$sims, mean(rnorm(input$n, mean = 50, sd = 10)))\n  })\n  \n  output$distPlot &lt;- renderPlot({\n    means &lt;- sample_means()\n    hist(means, breaks = 30, col = \"#007bc2\", border = \"white\",\n         main = paste(\"Distribution of\", input$sims, \"Means (n =\", input$n, \")\"),\n         xlab = \"Sample Mean Value\")\n    abline(v = 50, col = \"red\", lwd = 2, lty = 2) # Population Mean\n  })\n}\n\nshinyApp(ui, server)",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Distribution of Sample Means</span>"
    ]
  },
  {
    "objectID": "hyp_test.html",
    "href": "hyp_test.html",
    "title": "15  Hypothesis Testing",
    "section": "",
    "text": "15.1 Purpose of Hypothesis Testing\nBehavioral scientists often can’t measure all individuals in a population.\nEx. Measuring the inhibition of all lawyers in the United States\nUse samples to test a hypothesis that is made about the population.\nExpose a sample to your IV, evaluate the results, and make an inference that the same effect would be seen in the population if you could actually measure everyone.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "hyp_test.html#steps-of-hypothesis-testing",
    "href": "hyp_test.html#steps-of-hypothesis-testing",
    "title": "15  Hypothesis Testing",
    "section": "15.2 Steps of Hypothesis Testing",
    "text": "15.2 Steps of Hypothesis Testing\n\nState the Hypothesis\n\nNull Hypothesis\n\nH0\nThe treatment had no effect on the DV\n\nAlternative Hypothesis\n\nH1\nThe treatment does have an effect on the DV\n\n\nSet the decision criteria\n\nAlpha (α)\nThe alpha value tells us how willing we are to make a mistake (as there is never a flawless study) and what probability of error we are willing to accept.\nIn social sciences less than 5% probability (p) is acceptable\nα = .05 = 5% = 5/100\nProbability of error (p) should be &lt; .05\n\nCollect data and compute statistic\n\nT test, Correlation, ANOVA\n\nMake a decision\n\nCan reject the null hypothesis or fail to reject the null hypothesis\nReject the Null hypothesis\n\nClaims there no significant effect\n\nFail to Reject the Null Hypothesis\n\nClaims there is a significant effect\n\nThere is a 5% chance of making a mistake (false positive or false negative)",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "hyp_test.html#decision-making-errors",
    "href": "hyp_test.html#decision-making-errors",
    "title": "15  Hypothesis Testing",
    "section": "15.3 Decision Making Errors",
    "text": "15.3 Decision Making Errors\nType 1 Error (False Positive)\nRejecting a true Null hypothesis, claiming there is a significant effect when there really is not.\nEx. Claiming that a medical treatment will cure cancer, but it does not.\nType II Error (False Negative)\nFailing to reject a false Null Hypothesis, claiming there is not a significant effect when there really is.\nEx. Claiming there is no difference between smokers and non-smokers, but there really is.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "hyp_test.html#hypothesis-testing-table",
    "href": "hyp_test.html#hypothesis-testing-table",
    "title": "15  Hypothesis Testing",
    "section": "15.4 Hypothesis Testing Table",
    "text": "15.4 Hypothesis Testing Table\nUse this table to help you determine whether the correct decision has been made about the Null and Alternative Hypotheses.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "hyp_test.html#assumptions-of-hypothesis-testing",
    "href": "hyp_test.html#assumptions-of-hypothesis-testing",
    "title": "15  Hypothesis Testing",
    "section": "15.5 Assumptions of Hypothesis Testing",
    "text": "15.5 Assumptions of Hypothesis Testing\nThe variability of scores and the number of scores in a sample influence the results of a hypothesis test, so several assumptions must be met before conducting one.\n\nMust have random sampling\nMust have independent observations\nThe value of sigma must remain unchanged by the treatment\nThe data must form a normal sampling distribution",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Hypothesis Testing</span>"
    ]
  },
  {
    "objectID": "t_tests.html",
    "href": "t_tests.html",
    "title": "16  T-tests",
    "section": "",
    "text": "16.1 Introduction\nT-tests compare means and help us determine if group differences we observe are statistically significant. In this chapter you will learn how to:",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>T-tests</span>"
    ]
  },
  {
    "objectID": "t_tests.html#introduction",
    "href": "t_tests.html#introduction",
    "title": "16  T-tests",
    "section": "",
    "text": "Run one sample, independent, and paired t-tests in R\nInterpret output from t tests\nTest the assumptions of t tests\nCreate APA style results using the report and apaTables packages",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>T-tests</span>"
    ]
  },
  {
    "objectID": "t_tests.html#pre-requisites",
    "href": "t_tests.html#pre-requisites",
    "title": "16  T-tests",
    "section": "16.2 Pre-requisites",
    "text": "16.2 Pre-requisites\nThis chapter will be using different packages in R to make calculating t-tests easier. One function we will be using is the t_test function from the rstatix package which utilizes the following formula (x = DV ~ 1, mu = number). The 1 after the ~ is used for one sample t tests because we aren’t comparing two samples. You will also need to load up the following packages.\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.6\n✔ forcats   1.0.1     ✔ stringr   1.6.0\n✔ ggplot2   4.0.1     ✔ tibble    3.3.0\n✔ lubridate 1.9.4     ✔ tidyr     1.3.1\n✔ purrr     1.2.0     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(rstatix)\n\n\nAttaching package: 'rstatix'\n\nThe following object is masked from 'package:stats':\n\n    filter\n\nlibrary(report)\nlibrary(apaTables)\n\nTIP: Make note of the warning that comes after loading rstatix because it says that the use of the filter() function now falls under the use of rstatix so the regular stats filter must be called directly if you want to use it but we will be using rstatix in this chapter.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>T-tests</span>"
    ]
  },
  {
    "objectID": "t_tests.html#what-is-a-t-test",
    "href": "t_tests.html#what-is-a-t-test",
    "title": "16  T-tests",
    "section": "16.3 What is a t-test?",
    "text": "16.3 What is a t-test?\nA t-test is an inferential statistic that compares means while also making note of variability and sample sizes. There are different ways in psychology that we can use these tests.\n\n16.3.1 One-sample t-test\nWhen we want to compare one group against a known value like for example the population average this is when we will use a one-sample t-test because we are only taking one group and applying it to a value that is already known.\nEx. Comparing USI college athletes’ (our sample) body fat percentage to the national average college student (our population) body fat percentage.\n\n\n16.3.2 Independent samples t-test\nComparing two completely different groups in a between subjects design.\nEx. Comparing a group that received aromatherapy and a group that received no therapy on sinus health.\n\n\n16.3.3 Paired t-test\nComparing one condition a group experiences to another condition that some group experiences.\nEx. Comparing relaxation scores before a massage and after a massage.\n\n\n16.3.4 Now lets practice creating a small data-set that we could see in a real study that you might do for your project.\nLets say a researcher wants to see if listening to calming music will help reduce stress. In the experiment stress is measured on a scale of 0-100.\nThe hypothesis for this example is that students who listen to music will report lower stress levels.\n\nstress_data &lt;- data.frame(\n  group = c(rep(\"Control\", 8), rep(\"Music\", 8)),\n  stress = c(75, 80, 78, 82, 79, 76, 81, 74, \n             60, 65, 62, 58, 63, 61, 59, 64)\n)",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>T-tests</span>"
    ]
  },
  {
    "objectID": "t_tests.html#descriptive-statistics",
    "href": "t_tests.html#descriptive-statistics",
    "title": "16  T-tests",
    "section": "16.4 Descriptive Statistics",
    "text": "16.4 Descriptive Statistics\nNow we are going to go through some practice examples to help you get a better use of applying different t-tests to scenarios\n\n16.4.1 Example using data\nNow lets run through an example fo using a one sample t-test in a psychology example\nDoes the average stress level in the music group differ from the control group?\nFirst we must separate the music only group into their own section from the control group then use the get_summary_stats function to get a summary of the stats from our previous data.\n\nstress_data %&gt;%\n  group_by(group) %&gt;%\n  get_summary_stats(stress, type = \"mean_sd\")\n\n# A tibble: 2 × 5\n  group   variable     n  mean    sd\n  &lt;chr&gt;   &lt;fct&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 Control stress       8  78.1  2.9 \n2 Music   stress       8  61.5  2.45\n\n\nAs you can see in the output above the results suggest that the people in the music group are less stressed than the people in the control group.\n\n\n16.4.2 Assumption Testing\nNow that we have our data it is important that we check to see if it is normal enough for a t-test by using the Shapiro-wilk test by using our stress variable\n\n\n16.4.3 Shapiro-Wilk test\nNow we must use the Shapiro-wilk test to see if p &gt; .05.\n\nstress_data %&gt;%\n  group_by(group) %&gt;%\n  shapiro_test(stress)\n\n# A tibble: 2 × 4\n  group   variable statistic     p\n  &lt;chr&gt;   &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 Control stress       0.954 0.753\n2 Music   stress       0.975 0.933\n\n\nAs you can see that our p value is &gt; than .05 so we can now run a t-test on it.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>T-tests</span>"
    ]
  },
  {
    "objectID": "t_tests.html#independent-sample-t-test",
    "href": "t_tests.html#independent-sample-t-test",
    "title": "16  T-tests",
    "section": "16.5 Independent Sample t-test",
    "text": "16.5 Independent Sample t-test\nNow lets take the data from before and use an independent sample t-test to see if our p value is &lt; .05 making it significant.\n\n16.5.1 Homogeneity of Variance\nWe need to use the homogeneity of variance test which is the levene_test for independent t-tests to see if we are able to conduct a t-test on our data\n\nstress_data %&gt;%\n  levene_test(stress ~ group)\n\n# A tibble: 1 × 4\n    df1   df2 statistic     p\n  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1     1    14     0.317 0.583\n\n\nAs you see in the output our F-value for this test is .317 which shows how the group variance is different compared to each other. So a low F-value means that variance is similar.\nThe p-value of .583 shows us that our assumption is met because variance is equal between groups.\n\n\n16.5.2 Practice with independent sample\nLets now take our data and run it through a t-test\n\nt_test(stress_data, stress ~ group)\n\n# A tibble: 1 × 8\n  .y.    group1  group2    n1    n2 statistic    df            p\n* &lt;chr&gt;  &lt;chr&gt;   &lt;chr&gt;  &lt;int&gt; &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;        &lt;dbl&gt;\n1 stress Control Music      8     8      12.4  13.6 0.0000000085\n\n\nAs you see in our output we get a lot of data so lets analyze each part of the output\nYou can see in group1 that this is the control group and group2 is the music group.\nThe n1 and n2 represent the participant number in each group which for this data set is 8\nThe t stat you can find under statistic this is 12.38 and it is a large t value which suggests a big difference between the variability of scores from the groups.\nOur p value for this test is 8.5e-09. This is a very small p value which indicates a statistically significant result which means that we reject the null hypothesis fro this experiment.\n\n\n16.5.3 APA Conclusion\nNow lets write a APA conclusion for the output that we have just analyzed above.\nParticipants in the music group reported significantly lowered stress (M = 12.38, SD = 2.45) than the control group ( M = 13.61, SD = 2.90), t(16) = 12.38, p &lt; .05.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>T-tests</span>"
    ]
  },
  {
    "objectID": "t_tests.html#one-sample-t-test-1",
    "href": "t_tests.html#one-sample-t-test-1",
    "title": "16  T-tests",
    "section": "16.6 One Sample t-test",
    "text": "16.6 One Sample t-test\nNow we can use the same data we just used to compare the mean from one group to a known population mean\n\n16.6.1 Running the t-test\nNow lets take the music group and use the known population mean which will be 70 in this example and compare that to the means of the people in our data\n\nmusic_only &lt;- stress_data %&gt;% filter(group == \"Music\")\nt_test(music_only, stress ~ 1, mu = 70)\n\n# A tibble: 1 × 7\n  .y.    group1 group2         n statistic    df         p\n* &lt;chr&gt;  &lt;chr&gt;  &lt;chr&gt;      &lt;int&gt;     &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n1 stress 1      null model     8     -9.81     7 0.0000242\n\n\nYou can see in this output that our sample mean is below the population mean we compared it to by seeing our statistic is -9.81 suggesting a large difference relative to variability. We also have a smaller p value than .05 so it means we can reject the null and that our sample mean differs from the population mean.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>T-tests</span>"
    ]
  },
  {
    "objectID": "t_tests.html#paired-t-test-1",
    "href": "t_tests.html#paired-t-test-1",
    "title": "16  T-tests",
    "section": "16.7 Paired t-test",
    "text": "16.7 Paired t-test\nWe use a paired t-test when we want to examine two scores before and after a group receives a stimulus.\nSo lets now do some practice imaging that we weant to see students stress levels before and after listening to some calming music\n\n16.7.1 Practice Problem\nFirst we need to create our data frame so we can use our data\n\npaired_data &lt;- data.frame(\n  student = 1:8,\n  stress_before = c(75, 80, 78, 82, 79, 76, 81, 74),\n  stress_after  = c(60, 65, 62, 58, 63, 61, 59, 64)\n)\n\n\n\n16.7.2 Checking for Normality\nNow we need to check for normality to see the difference of scores before and after treatment by using the Shapiro wick test.\n\npaired_data %&gt;%\n  mutate(diff = stress_before - stress_after) %&gt;%\n  shapiro_test(diff)\n\n# A tibble: 1 × 3\n  variable statistic     p\n  &lt;chr&gt;        &lt;dbl&gt; &lt;dbl&gt;\n1 diff         0.877 0.177\n\n\nSince we have a p &gt; .05 we can now run our paired t-test.\n\n\n16.7.3 Running the t-test\nNow we are going to be running our paired t-test to see if stress significantly decreased from the same participants after they have received the treatment.\n\nt.test(paired_data$stress_before,\n       paired_data$stress_after,\n       paired = TRUE)\n\n\n    Paired t-test\n\ndata:  paired_data$stress_before and paired_data$stress_after\nt = 10.673, df = 7, p-value = 1.39e-05\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 12.94169 20.30831\nsample estimates:\nmean difference \n         16.625 \n\n\n\n\n16.7.4 APA Conclusion\nNow that we have our output from our t-test we can use the report package to create an APA style conclusion for us automatically\n\npaired_test &lt;- t.test(paired_data$stress_before,\n                      paired_data$stress_after,\n                      paired = TRUE)\n\nreport(paired_test)\n\nFor paired samples, 'repeated_measures_d()' provides more options.\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Paired t-test testing the difference between paired_data$stress_before and\npaired_data$stress_after (mean difference = 16.62) suggests that the effect is\npositive, statistically significant, and large (difference = 16.62, 95% CI\n[12.94, 20.31], t(7) = 10.67, p &lt; .001; Cohen's d = 3.77, 95% CI [1.71, 5.81])\n\n\nOur output shows us that the effect is positive and significant and the treatment was effective.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>T-tests</span>"
    ]
  },
  {
    "objectID": "t_tests.html#apa-tables",
    "href": "t_tests.html#apa-tables",
    "title": "16  T-tests",
    "section": "16.8 APA Tables",
    "text": "16.8 APA Tables\nAPA tables is a very useful package that allows us to present our data in APA formatted tables\n\n16.8.1 Creating an APA Table\nNow we are going to create an APA table for us to use that combines our control and music groups.\n\napa.1way.table(\n  data = stress_data,\n  dv = stress,\n  iv = group,\n  filename = \"stress_ttest_table.doc\"\n)\n\n\n\nDescriptive statistics for stress as a function of group.  \n\n   group     M   SD\n Control 78.12 2.90\n   Music 61.50 2.45\n\nNote. M and SD represent mean and standard deviation, respectively.\n \n\n\nAs you can see APA tables creates a simple and detailed table that you can put into a word document when you are writing your final paper.",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>T-tests</span>"
    ]
  },
  {
    "objectID": "t_tests.html#report-package",
    "href": "t_tests.html#report-package",
    "title": "16  T-tests",
    "section": "16.9 Report Package",
    "text": "16.9 Report Package\nThe report package automatically formats any data or results into a APA style sentence that works very will for research papers\nIt generates an APA style paragraph that you can put right into your paper\n\nreport(paired_test)\n\nFor paired samples, 'repeated_measures_d()' provides more options.\n\n\nEffect sizes were labelled following Cohen's (1988) recommendations.\n\nThe Paired t-test testing the difference between paired_data$stress_before and\npaired_data$stress_after (mean difference = 16.62) suggests that the effect is\npositive, statistically significant, and large (difference = 16.62, 95% CI\n[12.94, 20.31], t(7) = 10.67, p &lt; .001; Cohen's d = 3.77, 95% CI [1.71, 5.81])",
    "crumbs": [
      "Statstics",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>T-tests</span>"
    ]
  }
]